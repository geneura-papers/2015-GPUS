WHO	TYPE	SUBTYPE	REAL PROBLEM	PT	AUTHORS	TITLE	SOURCE	YEAR	ABSTRACT
JJ	ALL	SURVEY	YES	J	Gong, Yue-Jiao; Chen, Wei-Neng; Zhan, Zhi-Hui; Zhang, Jun; Li, Yun; Zhang, Qingfu; Li, Jing-Jing	Distributed evolutionary algorithms and their models: A survey of the state-of-the-art	APPLIED SOFT COMPUTING	2015	The increasing complexity of real-world optimization problems raises new challenges to evolutionary computation. Responding to these challenges, distributed evolutionary computation has received considerable attention over the past decade. This article provides a comprehensive survey of the state-of-the-art distributed evolutionary algorithms and models, which have been classified into two groups according to their task division mechanism. Population-distributed models are presented with master-slave, island, cellular, hierarchical, and pool architectures, which parallelize an evolution task at population, individual, or operation levels. Dimension-distributed models include coevolution and multi-agent models, which focus on dimension reduction. Insights into the models, such as synchronization, homogeneity, communication, topology, speedup, advantages and disadvantages are also presented and discussed. The study of these models helps guide future development of different and/or improved algorithms. Also highlighted are recent hotspots in this area, including the cloud and MapReduce-based implementations, GPU and CUDA-based implementations, distributed evolutionary multiobjective optimization, and real-world applications. Further, a number of future research directions have been discussed, with a conclusion that the development of distributed evolutionary computation will continue to flourish. (C) 2015 Elsevier B.V. All rights reserved.
JJ	ALL	SURVEY	YES	J	Ding Ke; Tan Ying	A review on general purpose computing on GPUs and its applications in computational intelligence	CAAI Transactions on Intelligent Systems	2015	The GPU enjoys the characteristics of high parallelism, low energy consumption and cheap price. Compared with the traditional CPU platform, it is especially suitable for tasks with high data parallelism. GPU computing has come into the mainstream of high performance computation (HPC) due to the emerging of development platforms like CUDA and OpenCL. The GPU's enormous computational power greatly promotes computational intelligence. A great success has been achieved in the fields such as deep learning and swarm intelligence optimization， and several breakthroughs have been seen in image, and speech recognition because of GPU. Though suffering some drawbacks, GPUs provide common people and small institutions with enormous computing power. This has changed the set-up of scientific computing and programming model because it could only be provided by expensive supercomputers. To help researchers in the field of computational intelligence better utilize GPUs, a detailed survey of GPGPU is given in this paper。First, the characteristics and advantages of GPUs against CPUs are presented. Then we briefly review the development of GPU hardware followed by a survey of the evolution of development tools for GPGPU; special attention is drawn to two major platforms, CUDA and OpenCL. We end this paper with our perspectives of the challenges and trends of GPGPU. We point out that embedding and cluster are two major trends for GPGPU and as both academia and industry continue to see increasing progress in artificial intelligence, the GPU will be more widely used in more domains.
ANTONIO	ALL	SURVEY	YES	S	Wang, Hongjian; Creput, Jean-Charles	Parallel and Distributed Implementation Models for Bio-inspired Optimization Algorithms	SWARM INTELLIGENCE BASED OPTIMIZATION (ICSIBO 2014)	2014	Bio-inspired optimization algorithms have natural parallelism but practical implementations in parallel and distributed computational systems are nontrivial. Gains from different parallelism philosophies and implementation strategies may vary widely. In this paper, we contribute with a new taxonomy for various parallel and distributed implementation models of metaheuristic optimization. This taxonomy is based on three factors that every parallel and distributed metaheuristic implementation needs to consider: control, data, and memory. According to our taxonomy, we categorize different parallel and distributed bio-inspired models as well as local search metaheuristic models. We also introduce a new designed GPU parallel model for the Kohonen's self-organizing map, as a representative example which belongs to a significant category in our taxonomy.
GUSTAVO	ALL	SURVEY	YES	J	Zhang Qingke; Yang Bo; Wang Lin; Zhu Fuxiang	Research on Parallel Modern Optimization Algorithms Using GPU	Computer Science	2012	In order to deal with the relatively high time-complexity of practical issue,parallel modern optimization based on GPU was presented in this paper.Firstly,CUDA parallel programming architecture and programming model were summarized at a macroscopic level.Then the parallel processes of five typical modern optimization algorithms(Simulated Annealing,Tabu Search,Genetic Algorithms,Particle Swarm Optimization and Artificial Neural Network) using CUDA programming model were provided.Experimental statistics measured in different environment indicate that the parallel method can obtain better performance on average than CPU.Finally the parallel optimization strategy was discussed and the outlook of future direction of parallel optimization algorithm was also pointed out.
GUSTAVO	ANN		no	J	Chedjou, J. C.; Kyamakya, K.	CNN-based ultrafast solver of stiff ODEs and PDEs for enabling realtime Computational Engineering	COMPEL-THE INTERNATIONAL JOURNAL FOR COMPUTATION AND MATHEMATICS IN ELECTRICAL AND ELECTRONIC ENGINEERING	2011	"Purpose - This paper seeks to develop, propose and validate, through a series of presentable examples, a comprehensive high-precision and ultra-fast computing concept for solving stiff ordinary differential equations (ODEs) and partial differential equations (PDEs) with cellular neural networks (CNN).Design/methodology/approach - The core of the concept developed in this paper is a straightforward scheme that we call ""nonlinear adaptive optimization (NAOP)"", which is used for a precise template calculation for solving any (stiff) nonlinear ODEs through CNN processors.Findings - One of the key contributions of this work (this is a real breakthrough) is to demonstrate the possibility of mapping/transforming different types of nonlinearities displayed by various classical and well-known oscillators (e.g. van der Pol-, Rayleigh-, Duffing-, Rossler-, Lorenz-, and Jerk-oscillators, just to name a few) unto first-order CNN elementary cells, and thereby enabling the easy derivation of corresponding CNN-templates. Furthermore, in case of PDEs solving, the same concept also allows a mapping unto first-order CNN cells while considering one or even more nonlinear terms of the Taylor's series expansion generally used in the transformation of a PDEs in a set of coupled nonlinear ODEs. Therefore, the concept of this paper does significantly contribute to the consolidation of CNN as a universal and ultra-fast solver of stiff differential equations (both ODEs and PDEs). This clearly enables a CNN-based, real-time, ultra-precise, and low-cost Computational Engineering. As proof of concept a well-known prototype of stiff equations (van der Pol) has been considered; the corresponding precise CNN-templates are derived to obtain precise solutions of this equation.Originality/value - This paper contributes to the enrichment of the literature as the relevant state-of-the-art does not provide a systematic and robust method to solve nonlinear ODEs and/or nonlinear PDEs using the CNN-paradigm. Further, the ""NAOP"" concept developed in this paper has been proven to perform accurate and robust calculations. This concept is not based on trial-and-error processes as it is the case for various classes of optimization methods/tools (e.g. genetic algorithm, particle swarm, neural networks, etc.). The ""NAOP"" concept developed in this frame does significantly contribute to the consolidation of CNN as a universal and ultra-fast solver of nonlinear differential equations (both ODES and PDEs). An implantation of the concept developed is possible even on embedded digital platforms (e.g. field-programmable gate array (FPGA), digital signal processing (DSP), graphics processing unit (GPU), etc.); this opens a broad range of applications. On-going works (as outlook) are using NAOP for deriving precise templates for a selected set of practically interesting PDE models such as Navier Stokes, Schrodinger, Maxwell, etc."
PEDRO	CFO		NO	J	Green, Robert C., II; Wang, Lingfeng; Alam, Mansoor; Formato, Richard A.	Central force optimization on a GPU: a case study in high performance metaheuristics	JOURNAL OF SUPERCOMPUTING	2012	Central Force Optimization (CFO) is a new and deterministic population based metaheuristic algorithm that has been demonstrated to be competitive with other metaheuristic algorithms such as Genetic Algorithms (GA), Particle Swarm Optimization (PSO), and Group Search Optimization (GSO). While CFO often shows superiority in terms of functional evaluations and solution quality, the algorithm is complex and typically requires increased computational time. In order to decrease the computational time required for convergence when using CFO, this study presents the first parallel implementation of CFO on a Graphics Processing Unit (GPU) using the NVIDIA Compute Unified Device Architecture (CUDA). Two versions of the CFO algorithm, Parameter-Free CFO (PF-CFO) and Pseudo-Random CFO (PR-CFO), are implemented using CUDA on a NVIDIA Quadro 1000M and examined using four test problems ranging from 10 to 50 dimensions. Discussion is made concerning the implementation of the CFO algorithms in terms of problem decomposition, memory access, scalability, and divergent code. Results demonstrate substantial speedups ranging from roughly 1 to 28 depending on problem size and complexity.
ANTONIO	DE	PSO	YES	S	Ugolotti, Roberto; Micconi, Giorgio; Aleotti, Jacopo; Cagnoni, Stefano	GPU-Based Point Cloud Recognition Using Evolutionary Algorithms	APPLICATIONS OF EVOLUTIONARY COMPUTATION	2014	In this paper, we describe a method for recognizing objects in the form of point clouds acquired with a laser scanner. This method is fully implemented on GPU and uses bio-inspired metaheuristics, namely PSO or DE, to evolve the rigid transformation that best aligns some references extracted from a dataset to the target point cloud. We compare the performance of our method with an established method based on Fast Point Feature Histograms (FPFH). The results prove that FPFH is more reliable under simple and controlled situations, but PSO and DE are more robust with respect to common problems as noise or occlusions.
MARIBEL	DE		YES	S	Ugolotti, Roberto; Mesejo, Pablo; Nashed, Youssef S. G.; Cagnoni, Stefano	GPU-Based Automatic Configuration of Differential Evolution: A Case Study	PROGRESS IN ARTIFICIAL INTELLIGENCE, EPIA 2013	2013	The performance of an evolutionary algorithm strongly depends on the choice of the parameters which regulate its behavior. In this paper, two evolutionary algorithms (Particle Swarm Optimization and Differential Evolution) are used to find the optimal configuration of parameters for Differential Evolution. We tested our approach on four benchmark functions, and the comparison with an exhaustive search demonstrated its effectiveness. Then, the same method was used to tune the parameters of Differential Evolution in solving a real-world problem: the automatic localization of the hippocampus in histological brain images. The results obtained consistently outperformed the ones achieved using manually-tuned parameters. Thanks to a GPU-based implementation, our tuner is up to 8 times faster than the corresponding sequential version.
MARIBEL	DE		YES	S	Cardenas-Montes, Miguel; Angel Vega-Rodriguez, Miguel; Sevilla, Ignacio; Ponce, Rafael; Jose Rodriguez-Vazquez, Juan; Sanchez Alvaro, Eusebio	Concurrent CPU-GPU Code Optimization: The Two-Point Angular Correlation Function as Case Study	ADVANCES IN ARTIFICIAL INTELLIGENCE, CAEPIA 2013	2013	Nowadays many computational systems are endowed of multi-cores in the main processor units, and one or more many-core cards. This makes possible the execution of codes on both computational resources concurrently. The challenge in this scenario is to balance correctly both execution paths. When the scenario is simple enough, by-hand optimization can be affordable, otherwise metaheuristic techniques are mandatory. In this work, Differential Evolution algorithm is implemented to optimize a concurrent CPU-GPU code calculating the Two-Point Angular Correlation Function applied to the study of Large-Scale Structure of the Universe. The Two-Point Angular Correlation Function is a computationally intensive function, requiring the calculation of three histograms with different execution times. Therefore, this forces to implement a parameter for describing the percentage of computation in CPU per histogram, and the counterpart in GPU; and to use metaheuristic techniques to fit the appropriate values for these three percentages. As a consequence of the optimization process described in this article, a significant reduction of the execution time is achieved. This proof of concept demonstrates that Evolutionary Algorithms are useful for fairly balancing computational paths in concurrent computing scenarios.
MARIBEL	DE		YES	S	Kroemer, Pavel; Platos, Jan; Snasel, Vaclav	A Brief Survey of Differential Evolution on Graphic Processing Units	PROCEEDINGS OF THE 2013 IEEE SYMPOSIUM ON DIFFERENTIAL EVOLUTION (SDE)	2013	Differential evolution is an efficient populational meta-heuristic optimization algorithm that has been applied to many difficult real world problems. Due to the relative simplicity of its operations and real encoded data structures, it is suitable for a parallel implementation on multicore systems and on Graphic Processing Units (GPUs) that nowadays reach peak performance of hundreds and thousands of giga FLOPS (floating-point operations per second). This study provides a brief survey of current state-of-the-art research on differential evolution in the GPU environment.
MARIBEL	DE		YES	S	de Oliveira, Fernando Bernardes; Davendra, Donald; Guimaraes, Frederico Gadelha	Multi-Objective Differential Evolution on the GPU with C-CUDA	SOFT COMPUTING MODELS IN INDUSTRIAL AND ENVIRONMENTAL APPLICATIONS	2013	In some applications, evolutionary algorithms may require high computational resources and high processing power, sometimes not producing a satisfactory solution after running for a considerable amount of time. One possible improvement is a parallel approach to reduce the response time. This work proposes to study a parallel multi-objective algorithm, the multi-objective version of Differential Evolution (DE). The generation of trial individuals can be done in parallel, greatly reducing the overall processing time of the algorithm. A novel approach to parallelize this algorithm is the implementation on the Graphic Processing Units (GPU). These units present high degree of parallelism and they were initially developed for image rendering. However, NVIDIA has released a framework, named CUDA, which allows developers to use GPU for general-purpose computing (GPGPU). This work studies the implementation of Multi-Objective DE (MODE) on the GPU with C-CUDA, evaluating the gain in processing time against the sequential version. Benchmark functions are used to validate the implementation and to confirm the efficiency of MODE on the GPU. The results show that the approach achieves an expressive speed up and a highly efficient processing power.
PEDRO	DE		NO	J	Fabris, Fabio; Krohling, Renato A.	A co-evolutionary differential evolution algorithm for solving min-max optimization problems implemented on GPU using C-CUDA	EXPERT SYSTEMS WITH APPLICATIONS	2012	Several areas of knowledge are being benefited with the reduction of the computing time by using the technology of graphics processing units (GPU) and the compute unified device architecture (CUDA) platform. In case of evolutionary algorithms, which are inherently parallel, this technology may be advantageous for running experiments demanding high computing time. In this paper, we provide an implementation of a co-evolutionary differential evolution (DE) algorithm in C-CUDA for solving min-max problems. The algorithm was tested on a suite of well-known benchmark optimization problems and the computing time has been compared with the same algorithm implemented in C. Results demonstrate that the computing time can significantly be reduced and scalability is improved using C-CUDA. As far as we know, this is the first implementation of a co-evolutionary DE algorithm in C-CUDA. (C) 2011 Elsevier Ltd. All rights reserved.
PEDRO	DE		NO	B	Davendra, Donald; Gaura, Jan; Bialic-Davendra, Magdalena; Senkerik, Roman	CUDA BASED ENHANCED DIFFERENTIAL EVOLUTION: A COMPUTATIONAL ANALYSIS	PROCEEDINGS 26TH EUROPEAN CONFERENCE ON MODELLING AND SIMULATION ECMS 2012	2012	General purpose graphic programming unit (GPGPU) programming is a novel approach for solving parallel variable independent problems. The graphic processor core (GPU) gives the possibility to use multiple blocks, each of which contains hundreds of threads. Each of these threads can be visualized as a core onto itself, and tasks can be simultaneously sent to all the threads for parallel evaluations. This research explores the advantages of applying a evolutionary algorithm (EA) on the GPU in terms of computational speedups. Enhanced Differential Evolution (EDE) is applied to the generic permutative flowshop scheduling (PFSS) problem both using the central processing unit (CPU) and the GPU, and the results in terms of execution time is compared.
PEDRO	DE		NO	S	Arabas, Jaroslaw; Maitre, Ogier; Collet, Pierre	PARADE: A Massively Parallel Differential Evolution Template for EASEA	SWARM AND EVOLUTIONARY COMPUTATION	2012	This paper presents an efficient PARAllelization of Differential Evolution on GPU hardware written as an EASEA (EAsy Specification of Evolutionary Algorithms) template for easy reproducibility and re-use. We provide results of experiments to illustrate the relationship between population size and efficiency of the parallel version based on GPU related to the sequential version on the CPU. We also discuss how the population size influences the number of generations to obtain a certain level of result quality.
PEDRO	DE		YES	S	Qin, A. K.; Raimondo, Federico; Forbes, Florence; Ong, Yew Soon	An Improved CUDA-Based Implementation of Differential Evolution on GPU	PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE	2012	Modern GPUs enable widely affordable personal computers to carry out massively parallel computation tasks. NVIDIA's CUDA technology provides a wieldy parallel computing platform. Many state-of-the-art algorithms arising from different fields have been redesigned based on CUDA to achieve computational speedup. Differential evolution (DE), as a very promising evolutionary algorithm, is highly suitable for parallelization owing to its data-parallel algorithmic structure. However, most existing CUDA-based DE implementations suffer from excessive low-throughput memory access and less efficient device utilization. This work presents an improved CUDA-based DE to optimize memory and device utilization: several logically-related kernels are combined into one composite kernel to reduce global memory access; kernel execution configuration parameters are automatically determined to maximize device occupancy; streams are employed to enable concurrent kernel execution to maximize device utilization. Experimental results on several numerical problems demonstrate superior computational time efficiency of the proposed method over two recent CUDA-based DE and the sequential DE across varying problem dimensions and algorithmic population sizes.
PEDRO	DE		NO	S	Zhou, Xinyu; Wu, Zhijian; Wang, Hui	Elite Opposition-based Differential Evolution for Solving Large-scale Optimization Problems and Its Implementation on GPU	2012 13TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS, AND TECHNOLOGIES (PDCAT 2012)	2012	Recently, the interests of solving large-scale optimization problems have increased in the field of evolutionary algorithms. This paper presents a novel differential evolution, namely EOBDE, to solve these kinds of problems by using elite opposition-based learning strategy. In the proposed algorithm, the opposite solutions of some selected elite individuals from the current population are generated at a certain probability for generation jumping. Then a corresponding opposite population is constructed to compete with the current population for providing more chances of finding out the global optimum. This approach is helpful to obtain a tradeoff between exploration and exploitation ability of DE. As another contribution, a parallel version of the proposed algorithm is implemented on Graphics Processing Units (GPU) based on CUDA platform for accelerating computing speed. The experiments are carried out on a set of representative problems with D=500 and 1000. The results of EOBDE are compared with other four state-of-the-art evolutionary algorithms in order to investigate the performance, which show that our proposed algorithm outperform the compared algorithms in terms of solution accuracy. Also the parallel version based on GPU shows promising performance in terms of the computational time.
ANTONIO	EDA	UMDA	YES	S	de Souza, Murilo Zangari; Ramirez Pozo, Aurora Trinidad	Parallel MOEA/D-ACO on GPU	ADVANCES IN ARTIFICIAL INTELLIGENCE (IBERAMIA 2014)	2014	This paper describes the idea of MOEA/D-ACO (Multiobjective Evolutionary Algorithm based on Decomposition and Ant Colony Optimization) and proposes a Graphics Processing Unit (GPU) implementation of MOEA/D-ACO using NVIDIA CUDA (Compute Unified Device Architecture) in order to improve the execution time. ACO is well-suited to GPU implementation, and both the solution construction and pheromone update phase are implemented using a data parallel approach. The parallel implementation is applied on the Multiobjective 0-1 Knapsack Problem and the Multiobjective Traveling Salesman Problem and reports speedups up to 19x and 11x respectively from the sequential counterpart with similar quality results. Moreover, the results show that the size of test instances, the number of objectives and the number of subproblems directly affect the speedup.
GUSTAVO	ES		no	J	Zhu, Weihang	Nonlinear optimization with a massively parallel Evolution Strategy-Pattern Search algorithm on graphics hardware	APPLIED SOFT COMPUTING	2011	This paper presents a massively parallel Evolution Strategy-Pattern Search Optimization (ES-PS) algorithm with graphics hardware acceleration on bound constrained nonlinear continuous optimization problems. The algorithm was specifically designed for a graphic processing unit (GPU) hardware platform featuring 'Single Instruction Multiple Thread' (SIMT). Evolution Strategy is a population-based evolutionary algorithm for solving complex optimization problems. GPU computing is an emerging desktop parallel computing platform. The hybrid ES-PS optimization method was implemented in the GPU environment and compared to a similar implementation on Central Processing Units (CPU). Computational results indicated that GPU-accelerated SIMT-ES-PS method was orders of magnitude faster than the corresponding CPU implementation. The main contribution of this paper was the parallelization analysis and performance analysis of the hybrid ES-PS with GPU acceleration. The computational results demonstrated a promising direction for high speed optimization with desktop parallel computing on a personal computer (PC). (C) 2010 Elsevier B.V. All rights reserved.
PABLO	ES		NO	B	Zhu, Weihang	A Study of Parallel Evolution Strategy - Pattern Search on a GPU Computing Platform	WORLD SUMMIT ON GENETIC AND EVOLUTIONARY COMPUTATION (GEC 09)	2009	This paper presents a massively parallel Evolution Strategy Pattern Search Optimization (ES-PS) algorithm with graphics hardware acceleration on bound constrained nonlinear continuous optimization functions. The algorithm is specifically designed for a graphic processing unit (CPU) hardware platform featuring 'Single Instruction Multiple Thread' (SIMT). CPU computing is an emerging desktop parallel computing platform. The hybrid ES-PS optimization method is implemented in the GPU environment and compared to a similar implementation on CPU hardware. Computational results indicate that CPU-accelerated SIMT-ES-PS method is orders of magnitude faster than the corresponding CPU implementation. The main contribution of this paper is the parallelization analysis and performance analysis of the hybrid ES-PS with CPU acceleration.
JJ	GA	ML	YES	J	Franco, Maria A.; Bacardit, Jaume	Large-scale experimental evaluation of GPU strategies for evolutionary machine learning	INFORMATION SCIENCES	2016	Graphics Processing Units (GPUs) are effective tools for improving the efficiency of many computationally demanding algorithms. GPUs have been particularly effective at speeding up the evaluation stage of evolutionary machine learning systems. The speedups obtained in these tasks, depend on many factors: dataset characteristics, the parallel strategy of the CPU code and the fit of the GPU code within the rest of the learning system. A solid understanding of all these factors is required to choose and adjust the most suitable GPU strategy in different scenarios. In this paper we present a large-scale performance evaluation of two GPU strategies for speeding up the evaluation of evolutionary machine learning systems. We use highly-tuneable synthetic problems to exhaustively explore the space of problem characteristics and determine the type of problems where each strategy performs best. The lessons learnt from this extensive evaluation are further confirmed by running experiments on a broad range of real-world datasets. Through this thorough evaluation we obtain a solid understanding of the capabilities and limitations of the evaluated GPU strategies for boosting the efficiency of evolutionary machine learning systems. (C) 2015 Elsevier Inc. All rights reserved.
JJ	GA	NN	YES	J	Sotiropoulos, Panagiotis; Kolonias, Vasileios; Aspragathos, Nikos; Housos, Efthymios	Rapid motion planning algorithm for optimal UVMS interventions in semi-structured environments using GPUs	ROBOTICS AND AUTONOMOUS SYSTEMS	2015	In this work, a novel local motion planning algorithm is presented, for underwater vehicle manipulator systems (UVMS) that perform autonomous underwater inspection operations. An optimization problem is formulated considering the collision avoidance, the approximation of the given task curve and critical optimization criteria. The searching method is based on an evolutionary algorithm and it is able to generate a local motion plan using continuously updated sensor information. The working environment is represented by a Bump-surface entity, constantly updated by a parallel algorithm implemented on a graphical processing unit (GPU). A trained artificial neural network is used for the fast approximation of the considered dexterity index. The local planner can cope with unknown obstacles inside the workspace while executing the task and pursuing high performance configurations in the free space. A welding inspection on an underwater tube structure is considered as the validation scenario, while a UVMS with a mounted six degrees of freedom manipulator is assigned to perform the task. (C) 2015 Elsevier B.V. All rights reserved.
JJ	GA		YES	J	Arca, Bachisio; Ghisu, Tiziano; Trunfio, Giuseppe A.	GPU-accelerated multi-objective optimization of fuel treatments for mitigating wildfire hazard	JOURNAL OF COMPUTATIONAL SCIENCE	2015	Fuel treatment is considered a suitable way to mitigate the hazard related to potential wildfires on a landscape. However, designing an optimal spatial layout of treatment units represents a difficult optimization problem. In fact, budget constraints, probabilistic nature of fire behaviour and complex interactions among the different fuel treatment patches, give rise to challenging search spaces on typical landscapes. In this study, we formulate the design problem in terms of a bi-objective optimization: minimizing both the extension of land characterized by high fire hazard and the cost of treatment. Then, we propose a computational approach that leads to a Pareto approximation set by exploiting an adapted version of the Non-dominated Sorting Genetic Algorithm II (NSGA-II) together with General-Purpose computing on Graphics Processing Units (GPGPU). Using an application example based on a real landscape, we also show that the proposed methodology has the potential to effectively support the design of a suitable fuel treatment for a landscape. (C) 2015 Elsevier B.V. All rights reserved.
JJ	GA		YES	J	Liu, Zhao-Hua; Li, Xiao-Hua; Wu, Liang-Hong; Zhou, Shao-Wu; Liu, Kan	GPU-Accelerated Parallel Coevolutionary Algorithm for Parameters Identification and Temperature Monitoring in Permanent Magnet Synchronous Machines	IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS	2015	A hierarchical fast parallel co-evolutionary immune particle swarm optimization (PS()) algorithm, accelerated by graphics processing unit (CPU) technique (C-PCIPS0), is proposed for multiparameter identification and temperature monitoring of permanent magnet synchronous machines (PMSM). It is composed of two levels and is developed based on compute unified device architecture (CUDA). In G-PCIPSO, the antibodies (Abs) of higher level memory are selected from the lower level swarms and improved by immune clonal-selection operator. The search information exchanges between swarms using the memory-based sharing mechanism. Moreover, an immune vaccine-enhanced operator is proposed to lead the Pbests particles to unexplored areas. Optimized parallel implementations of C-PCIPSO algorithm is developed on CPU using CUDA, which significantly speeds up the search process. Finally, the proposed algorithm is applied to multiple parameters identification and temperature monitoring of PMSM. It can track parameter variation and achieve temperature monitoring online effectively. Compared with a CPU-based serial execution, the computational efficiency is greatly enhanced by CPU-accelerated parallel computing technique.
JJ	GA	NN	YES	J	Bukharov, Oleg E.; Bogolyubov, Dmitry P.	Development of a decision support system based on neural networks and a genetic algorithm	EXPERT SYSTEMS WITH APPLICATIONS	2015	Given ever increasing information volume and complexity of engineering, social and economic systems, it has become more difficult to assess incoming data and manage such systems properly. Currently developed innovative decision support systems (DSS) aim to achieve optimum results while minimizing the risks of serious losses. The purpose of the DSS is to help the decision-maker facing the problem of huge amounts of data and ambiguous reactions of complicated systems depending on external factors. By means of accurate and profound analysis, DSSs are expected to provide the user with precisely forecasted indicators and optimal decisions.In this paper we suggest a new DSS structure which could be used in a wide range of difficult to formalize tasks and achieve a high speed of calculation and decision-making.We examine different approaches to determining the dependence of a target variable on input data and review the most common statistical forecasting methods. The advantages of using neural networks for this purpose are described. We suggest applying interval neural networks for calculations with underdetermined (interval) data, which makes it possible to use our DSS in a wide range of complicated tasks. We developed a corresponding learning algorithm for the interval neural networks. The advantages of using a genetic algorithm (GA) to select the most significant inputs are shown. We justify the use of general-purpose computing on graphics processing units (GPGPU) to achieve high-speed calculations with the decision support system in question. A functional diagram of the system is presented and described. The results and samples of the DSS application are demonstrated. (C) 2015 Elsevier Ltd. All rights reserved.
JJ	GA	NN	YES	J	Fe, Jorge D.; Aliaga, Ramon J.; Gadea-Girones, Rafael	Evolutionary optimization of neural networks with heterogeneous computation: study and implementation	JOURNAL OF SUPERCOMPUTING	2015	In the optimization of artificial neural networks (ANNs) via evolutionary algorithms and the implementation of the necessary training for the objective function, there is often a trade-off between efficiency and flexibility. Pure software solutions on general-purpose processors tend to be slow because they do not take advantage of the inherent parallelism, whereas hardware realizations usually rely on optimizations that reduce the range of applicable network topologies, or they attempt to increase processing efficiency by means of low-precision data representation. This paper presents, first of all, a study that shows the need of heterogeneous platform (CPU-GPU-FPGA) to accelerate the optimization of ANNs using genetic algorithms and, secondly, an implementation of a platform based on embedded systems with hardware accelerators implemented in Field Pro-grammable Gate Array (FPGA). The implementation of the individuals on a remote low-cost Altera FPGA allowed us to obtain a 3x-4x acceleration compared with a 2.83 GHz Intel Xeon Quad-Core and 6x-7x compared with a 2.2 GHz AMD Opteron Quad-Core 2354.
JJ	GA		YES	J	Pedemonte, Martin; Luna, Francisco; Alba, Enrique	Systolic genetic search, a systolic computing-based metaheuristic	SOFT COMPUTING	2015	In this paper, we propose a new parallel optimization algorithm that combines ideas from the fields of metaheuristics and Systolic Computing. The algorithm, called Systolic Genetic Search (SGS), is designed to explicitly exploit the high degree of parallelism available in modern Graphics Processing Unit (GPU) architectures. In SGS, solutions circulate synchronously through a grid of processing cells, which apply adapted evolutionary operators on their inputs to compute their outputs that are then ejected from the cells and continue moving through the grid. Four different variants of SGS are experimentally studied for solving two classical benchmarking problems and a real-world application. An extensive experimental analysis, which considered several instances for each problem, shows that three of the SGS variants designed are highly effective since they can obtain the optimal solution in almost every execution for the instances and problems studied, as well as they outperform a Random Search (sanity check) and two Genetic Algorithms. The parallel implementation on GPU of the proposed algorithm has achieved a high performance obtaining runtime reductions from the sequential implementation that, depending on the instance considered, can arrive to around a hundred times, and have also exhibited a good scalability behavior when solving highly dimensional problem instances.
JJ	GA		NO	J	Patvardhan, C.; Bansal, Sulabh; Srivastav, Anand	Quantum-Inspired Evolutionary Algorithm for difficult knapsack problems	MEMETIC COMPUTING	2015	Quantum Inspired Evolutionary Algorithms (QIEAs) are Evolutionary Algorithms which use concepts and principles of quantum computing. The 0/1 knapsack problem (KP) is a well known combinatorial optimization problem that has been typically used to validate the performance of QIEAs. However, there are some variants of KPs called difficult knapsack problems (DKPs) that are known to be more difficult to solve. QIEAs have not yet been fully explored for solving these. In this work, an improved QIEA, called QIEA-PSA is presented. A novel method to initialize the qubit individuals based on heuristic information for the KP instance and a method for size reduction for each new generation are introduced in the presented QIEA-PSA. Experiments are carried out for several types of DKPs that are much larger in size than those attempted hitherto. QIEA-PSA provides much better solutions than QIEA with much lesser computation times. Even a serial implementation of QIEA-PSA competes favorably on the same problem instances with a parallel implementation of an exact algorithm given recently in literature. A comparison is made which shows QIEA-PSA outperforms a recently applied population based search technique to solve benchmark KP instances. The ideas used for developing QIEA-PSA are general and may be utilized with advantage on other problems.
JJ	GA		YES	J	Zhang, Qiyao; Cheng, Longjiu	Structural Determination of (Al2O3)(n) (n=1-15) Clusters Based on Graphic Processing Unit	JOURNAL OF CHEMICAL INFORMATION AND MODELING	2015	Global optimization algorithms have been widely used in the field of chemistry to search the global minimum structures of molecular and atomize clusters, which is a nondeterministic polynomial problem with the increasing sizes of clusters. Considering that the computational ability Of a graphic processing unit (GPU) is Much better than that of a central processing unit :(CPU), we developed a GPU-based genetic algorithm for structural prediction of clusters and achieved a high acceleration ratio compared to a CPU. On the one-dimensional (1D) operation of a GPU, taking (Al2O3)(n) clusters as test cases, the peak acceleration ratio in the CPU is about 220 times that in a CPU in single precision and the value is 103 for double precision in calculation of the analytical interatomic potential. The peak acceleration ratio is about 240 and 107 on the block operation, and it is about 77 and 35 on the 2D operation compared to a CPU in single precision and double precision, respectively. And the peak acceleration ratio of the whole genetic algorithm program is about 35 compared to CPU at double precision. Structures of (Al2O3)(n) clusters at n = 1-10 reported in previous works are successfully located, and their low-lying structures at n = 11-15 are predicted.
JJ	GA		YES	J	Akgun, Devrim; Erdogmus, Pakize	GPU accelerated training of image convolution filter weights using genetic algorithms	APPLIED SOFT COMPUTING	2015	Genetic algorithms (GA) provide an efficient method for training filters to find proper weights using a fitness function where the input signal is filtered and compared with the desired output. In the case of image processing applications, the high computational cost of the fitness function that is evaluated repeatedly can cause training time to be relatively long. In this study, a new algorithm, called sub-image blocks based on graphical processing units (GPU), is developed to accelerate the training of mask weights using GA. The method is developed by discussing other alternative design considerations, including direct method (DM), population-based method (PBM), block-based method (BBM), and sub-images-based method (SBM). A comparative performance evaluation of the introduced methods is presented using sequential and other GPUs. Among the discussed designs, SBM provides the best performance by taking advantage of the block shared and thread local memories in GPU. According to execution duration and comparative acceleration graphs, SBM provides approximately 55-90 times more acceleration using GeForce GTX 660 over sequential implementation on a 3.5 GHz processor. (C) 2015 Elsevier B.V. All rights reserved.
JJ	GA		NO	J	Franz, Wayne; Thulasiraman, Parimala; Thulasiram, Ruppa K.	Exploration/exploitation of a hybrid-enhanced MPSO-GA algorithm on a fused CPU-GPU architecture	CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE	2015	Recent work in metaheuristic algorithms has shown that solution quality may be improved by composing algorithms with orthogonal characteristics. At the same time, fused CPU-GPU systems have emerged as a unique platform on which to study these algorithms. Using metaheuristic algorithms requires striking a balance between local and global exploration. There are no governing rules, however, to balance these. In this paper, we study two population-based metaheuristic algorithms: multi-swarm particle swarm optimization (MPSO) and genetic algorithms (GAs). We investigate parallel MPSO variants with genetic operators to increase quality: crossover, mutation, swapping, and all three. We develop a hybrid parallel algorithm that combines a slower convergent algorithm (GA) with a faster one (MPSO). The hybrid achieves significant initial improvement in solution quality but no significant difference in the final average fitness. Executing the GA on the GPU requires approximately an order of magnitude less time (0.07-0.18s) than on the CPU. Our platform is the AMD A8-3530MX accelerated processing unit that packs four x86 CPU cores and 80 very long instruction word GPU processing elements. We make effective use of the hierarchical memory structure on the accelerated processing unit, four-way very long instruction word vectorization, and zero-copy buffers. Copyright (c) 2014 John Wiley & Sons, Ltd.
JJ	GA		NO	J	Roberge, Vincent; Tarbouchi, Mohammed; Okou, Francis	Collaborative Parallel Hybrid Metaheuristics on Graphics Processing Unit	INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE AND APPLICATIONS	2015	Metaheuristics are nondeterministic optimization algorithms used to solve complex problems for which classic approaches are unsuitable. Despite their effectiveness, metaheuristics require considerable computational power and cannot easily be used in time critical applications. Fortunately, those algorithms are intrinsically parallel and have been implemented on shared memory systems and more recently on graphics processing units (GPUs). In this paper, we present highly effecient parallel implementations of the particle swarm optimization (PSO), the genetic algorithm (GA) and the simulated annealing (SA) algorithm on GPU using CUDA. Our approach exploits the parallelism at the solution level, follows an island model and allows for speedup up to 346x for different benchmark functions. Most importantly, we also present a strategy that uses the generalized island model to integrate multiple metaheuristics into a parallel hybrid solution adapted to the GPU. Our proposed solution uses OpenMP to heavily exploit the concurrent kernel execution feature of recent NVIDIA GPUs, allowing for the parallel execution of the different metaheuristics in an asynchronous manner. Asynchronous hybrid metaheuristics has been developed for multicore CPU, but never for GPU. The speedup offered by the GPU is far superior and key to the optimization of solutions to complex engineering problems.
JJ	GA		YES	J	Arranz, Alvaro; Alvar, Manuel	GPGPU Implementation of a Genetic Algorithm for Stereo Refinement	INTERNATIONAL JOURNAL OF INTERACTIVE MULTIMEDIA AND ARTIFICIAL INTELLIGENCE	2015	During the last decade, the general-purpose computing on graphics processing units Graphics (GPGPU) has turned out to be a useful tool for speeding up many scientific calculations. Computer vision is known to be one of the fields with more penetration of these new techniques. This paper explores the advantages of using GPGPU implementation to speedup a genetic algorithm used for stereo refinement. The main contribution of this paper is analyzing which genetic operators take advantage of a parallel approach and the description of an efficient state-of-the-art implementation for each one. As a result, speed-ups close to x80 can be achieved, demonstrating to be the only way of achieving close to real-time performance.
JJ	GA		NO	J	Lastra, Miguel; Molina, Daniel; Benitez, Jose M.	A high performance memetic algorithm for extremely high-dimensional problems	INFORMATION SCIENCES	2015	Throughout the last years, optimization problems on a large number of variables, sometimes over 1000, are becoming common. Thus, algorithms that can tackle them effectively, both in result quality and run time, are necessary. Among these specific algorithms for high-dimensional problems, memetic algorithms, which are the result of the hybridization of an evolutionary algorithm and a local improvement technique, have arisen as very powerful optimization systems for this type of problems. A very effective algorithm of this kind is the MA-SW-Chains algorithm. On the other hand, general purpose computing using Graphics Processing Units (GPUs) has become a very active field because of the high speed-up ratios that can be obtained when applied to problems that exhibit a high degree of data parallelism.In this work we present a new design of MA-SW-Chains to adapt it to the GPU-based massively parallel architecture. The experiments with the new GPU memetic technique, compared to the original sequential version, prove that the results are obtained with the same quality but with a reduction of the run time of two orders of magnitude. This great improvement in computing time makes our proposal suitable for future optimization problems with a dimensionality several orders of magnitude greater than current high-dimensionality standards (i.e. problems with millions of variables). The remarkable run time reduction comes at the cost of a higher design and implementation overhead compared to the GPU-based single-threaded counterpart. (C) 2014 Elsevier Inc. All rights reserved.
JJ	GA		YES	S	Li, Li; Zhang, Kai; Yang, Siman; He, Juanjuan	Parallel Hybrid Genetic Algorithm for Maximum Clique Problem on OpenCL	BIO-INSPIRED COMPUTING - THEORIES AND APPLICATIONS, BIC-TA 2015	2015	The maximum clique problem is to find the maximum sized clique of pairwise adjacent vertices in a given graph, which is a NP-Complete problem. In this paper, an effective parallel hybrid genetic algorithm is proposed, which consists of genetic algorithm and a local optimization strategy for solving maximum clique problem. In this algorithm, selection, crossover, mutation, fitness evaluation and replacement operators are implemented parallel on OpenCL. In addition, we have tested our algorithm by using a set of benchmark instances from the DIMACS graphs. The comparison results shows that the implementation on GPU provide better performance that CPU, even when the benchmark graphs become more large and complicate.
JJ	GA		NO	J	Lin Min; Zhong Yiwen	Three GPU-based parallel simulated annealing algorithm with adaptive neighborhood	Computer Engineering and Application	2015	Three new GPU-based parallel simulated annealing algorithms with adaptive neighborhood are proposed in this paper. They are parallel genetic-simulated annealing algorithm based on GPU, parallel annealing algorithm with multiple Markov chains, and parallel annealing algorithm based on block. Several novel strategies adopted in these algorithms such as coalescent memory access, avoiding bank conflict, and reduction improve the performance. The experiments tested on 11 typical benchmark functions show the new three algorithms have better accuracy and faster convergence speed than the nonu-SA algorithm.
JJ	GA		NO	J	Cardenas-Montes, Miguel; Vega-Rodriguez, Miguel A.	EFFECT OF DATA LAYOUT IN THE EVALUATION TIME OF NON-SEPARABLE FUNCTIONS ON GPU	COMPUTING AND INFORMATICS	2015	CPUs are able to provide a tremendous computational power, but their optimal usage requires the optimization of memory access. The many threads available can mitigate the long memory access latencies, but this usually demands a reorganization of the data and algorithm to reach the performance peak. The addressed problem is to know which data layout produces a faster evaluation when dealing with population-based evolutionary algorithms optimizing non-separable functions. This knowledge will allow a more efficient design of evolutionary algorithms. Depending on the fitness function and the problem size, the most suitable layout can be implemented at the design phase of the algorithm, avoiding later costly code or data layout redesigns. In this paper, diverse non-separable functions, such as Rosenbrock and Rana functions, and data layouts are evaluated. The implemented layouts cover main techniques to maximize the performance: coalesced access to global memory, intensive use of on-chip memory: shared memory and registers, and variable reuse to minimize the global memory transactions. Conclusions about the optimum data layout related to the characteristics of the fitness function and the problem size are stated. Besides, the conclusions ease the decision-making process for future implementations of other non-separable functions.
JJ	GA		NO	S	Wodecki, Mieczyslaw; Bozejko, Wojciech; Jagiello, Szymon; Pempera, Jaroslaw	Parallel Cost Function Determination on GPU for the Vehicle Routing Problem	ARTIFICIAL INTELLIGENCE AND SOFT COMPUTING, PT II (ICAISC 2015)	2015	The paper deals with parallel variants of optimization algorithms dedicated to solve transportation optimization issues. The problem derives from practice of logistics and vehicle routes planning. We propose parallelization method of the cost function determination dedicated to be executed on GPU architecture. The method can be used in metaheuristic algorithms as well as in exact approaches.(1)
JJ	GA		NO	S	Manoatl Lopez, Edgar; Miguel Antonio, Luis; Coello Coello, Carlos A.	A GPU-Based Algorithm for a Faster Hypervolume Contribution Computation	EVOLUTIONARY MULTI-CRITERION OPTIMIZATION, PT II	2015	The hypervolume has become very popular in current multiobjective optimization research. Because of its highly desirable features, it has been used not only as a quality measure for comparing final results of multi-objective evolutionary algorithms (MOEAs), but also as a selection operator (it is, for example, very suitable for many-objective optimization problems). However, it has one serious drawback: computing the exact hypervolume is highly costly. The best known algorithms to compute the hypervolume are polynomial in the number of points, but their cost grows exponentially with the number of objectives. This paper proposes a novel approach which, through the use of Graphics Processing Units (GPUs), computes in a faster way the hypervolume contribution of a point. We develop a highly parallel implementation of our approach and demonstrate its performance when using it within the S-Metric Selection Evolutionary Multi-Objective Algorithm (SMS-EMOA). Our results indicate that our proposed approach is able to achieve a significant speed up (of up to 883x) with respect to its sequential counterpart, which allows us to use SMS-EMOA with exact hypervolume calculations, in problems having up to 9 objective functions.
JJ	GA		YES	J	Han Qi; Cai Yong	An Efficient Parallel Implementation of Large - Scale Topology Optimization Problems Using GPU	Computer Simulation	2015	In this paper,a parallel topology optimization method is proposed to calculate large - scale structural design problems based on GPU. The parallel algorithms presented here are based on the Bi - directional Evolutionary Structural Optimization (BESO) formulation with soft - kill technology. Considering the characteristic of GPU computation,the conjugate gradient iterative solver with a nodal based visual finite element assembly scheme is introduced for the finite method problem. Compute Unified Device Architecture (CUDA) is employed to design and code program, including several high API offered by CUDA for free. Two parallel computing strategies include nodal -based and element - based mapping strategies. Finally, a total parallel optimization program is realized. Several numerical examples are considered, more than 100 times speedup can be obtained in handling large - scale design problems on a personal computing with a NVIDIA GTX 580 GPU. It shows the scalability and effectiveness of the present parallel approach.
ANTONIO	GA		YES	J	Karthik, Victor U.; Sivasuthan, Sivamayam; Rahunanthan, Arunasalam; Thyagarajan, Ravi S.; Jayakumar, Paramsothy; Udpa, Lalita; Hoole, S. Ratnajeevan H.	Faster, more accurate, parallelized inversion for shape optimization in electroheat problems on a graphics processing unit (GPU) with the real-coded genetic algorithm	COMPEL-THE INTERNATIONAL JOURNAL FOR COMPUTATION AND MATHEMATICS IN ELECTRICAL AND ELECTRONIC ENGINEERING	2015	Purpose - Inverting electroheat problems involves synthesizing the electromagnetic arrangement of coils and geometries to realize a desired heat distribution. To this end two finite element problems need to be solved, first for the magnetic fields and the joule heat that the associated eddy currents generate and then, based on these heat sources, the second problem for heat distribution. This two-part problem needs to be iterated on to obtain the desired thermal distribution by optimization. Being a time consuming process, the purpose of this paper is to parallelize the process using the graphics processing unit (GPU) and the real-coded genetic algorithm, each for both speed and accuracy.Design/methodology/approach - This coupled problem represents a heavy computational load with long wait-times for results. The GPU has recently been demonstrated to enhance the efficiency and accuracy of the finite element computations and cut down solution times. It has also been used to speedup the naturally parallel genetic algorithm. The authors use the GPU to perform coupled electroheat finite element optimization by the genetic algorithm to achieve computational efficiencies far better than those reported for a single finite element problem. In the genetic algorithm, coding objective functions in real numbers rather than binary arithmetic gives added speed and accuracy.Findings - The feasibility of the method proposed to reduce computational time and increase accuracy is established through the simple problem of shaping a current carrying conductor so as to yield a constant temperature along a line. The authors obtained a speedup (CPU time to GPU time ratio) saturating to about 28 at a population size of 500 because of increasing communications between threads. But this far better than what is possible on a workstation.Research limitations/implications - By using the intrinsically parallel genetic algorithm on a GPU, large complex coupled problems may be solved very quickly. The method demonstrated here without accounting for radiation and convection, may be trivially extended to more completely modeled electroheat systems. Since the primary purpose here is to establish methodology and feasibility, the thermal problem is simplified by neglecting convection and radiation. While that introduces some error, the computational procedure is still validated.Practical implications - The methodology established has direct applications in electrical machine design, metallurgical mixing processes, and hyperthermia treatment in oncology. In these three practical application areas, the authors need to compute the exciting coil (or antenna) arrangement (current magnitude and phase) and device geometry that would accomplish a desired heat distribution to achieve mixing, reduce machine heat or burn cancerous tissue. This process presented does it more accurately and speedily.Social implications - Particularly the above-mentioned application in oncology will alleviate human suffering through use in hyperthermia treatment planning in cancer treatment. The method presented provides scope for new commercial software development and employment.Originality/value - Previous finite element shape optimization of coupled electroheat problems by this group used gradient methods whose difficulties are explained. Others have used analytical and circuit models in place of finite elements. This paper applies the massive parallelization possible with GPUs to the inherently parallel genetic algorithm, and extends it from single field system problems to coupled problems, and thereby realizes practicable solution times for such a computationally complex problem. Further, by using GPU computations rather than CPU, accuracy is enhanced. And then by using real number rather than binary coding for object functions, further accuracy and speed gains are realized.
ANTONIO	GA	NN	YES	J	Nambiar, Vishnu P.; Khalil-Hani, Mohamed; Marsono, M. N.; Sia, C. W.	Optimization of structure and system latency in evolvable block-based neural networks using genetic algorithm	NEUROCOMPUTING	2014	This paper proposes a novel optimization method that utilizes a multi-population parallel genetic algorithm (GA) to simultaneously optimize the structure and system latency of evolvable block-based neural networks (BbNNs). In the past, BbNNs have been successfully deployed for various kinds of classification problems with promising results. However, existing BbNN architectures do not explicitly model or optimize the latency of the system. Optimization of system latency is important, because it improves performance, reduces power consumption, and allows a more deterministic behavior that is needed for recurrent modes. The BbNN hardware model proposed in this paper is implemented as a synchronous architecture with registered outputs. This architecture will permit the system latency to be deterministic. To facilitate the automated layout of the neuron block interconnects within the BbNN structure, an array interconnect algorithm is presented. The proposed latency-optimized BbNN is implemented in hardware, and the architecture resembles mobile devices with integrated graphics processing units (GPUs). The hardware implementation is verified and analyzed using various case studies. The power consumption of our prototyping platform was measured, and it is shown that approximately 364 nJ of energy can be saved for every computational cycle (latency) reduced. All presented case studies show that the proposed BbNN model provides an optimal latency value while still matching the high accuracy reported in previous works. (C) 2014 Elsevier B.V. All rights reserved.
ANTONIO	GA	LS	NO	J	Garcia-Martinez, J. M.; Garzon, E. M.; Ortigosa, P. M.	A GPU implementation of a hybrid evolutionary algorithm: GPuEGO	JOURNAL OF SUPERCOMPUTING	2014	The high computation requirements of global optimization algorithms, when used to solve real optimization problems, have caused the appearance of different parallelization strategies using several parallel computing architectures. In this work, the Universal Evolutionary Global Optimizer is implemented in CUDA to be run on GPU architectures (GPuEGO). This parallelization of the referred evolutionary multimodal optimization algorithm is rather different from other previous parallel implementations designed to be executed into shared or distributed memory processors. In this case, due to the special characteristics of a GPU architecture, the original data structures are not valid and it has been necessary to redefine them and all the functions that operate with them. When this approach is applied the acceleration factors achieved by GPuEGO range from 6.33 to 23.20 depending on the test function.
ANTONIO	GA		YES	J	Choi, Yoon-Seok; Jung, Soonchul; Kim, Jae Woo; Koo, Bon-Ki	Real-time video photomosaics with optimized image set and GPU	JOURNAL OF REAL-TIME IMAGE PROCESSING	2014	We propose a real-time approach to automatically generate photomosaic videos from a set of optimized images by taking advantage of CUDA GPU acceleration. Our approach divides an input image into smaller cells-usually rectangular cells-and replaces each cell with a small image of an appropriate color pattern. Photomosaics require a large set of tile images with a variety of patterns to create high-quality digital mosaic images. Because a large database of images requires longer processing time and larger storage space for searching patterns from the database, this requirement causes problems in developing a real-time system or mobile applications that have limited resources. This paper deals with a real-time video photomosaics using genetic feature selection method for building an optimized image set and taking advantage of CUDA to accelerate pattern searching that minimizes computation cost.
ANTONIO	GA		NO	J	Zheng, Long; Lu, Yanchao; Guo, Minyi; Guo, Song; Xu, Cheng-Zhong	Architecture-based design and optimization of genetic algorithms on multi- and many-core systems	FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF GRID COMPUTING AND ESCIENCE	2014	A Genetic Algorithm (GA) is a heuristic to find exact or approximate solutions to optimization and search problems within an acceptable time. We discuss GAs from an architectural perspective, offering a general analysis of performance of GAs on multi-core CPUs and on many-core GPUs. Based on the widely used Parallel GA (PGA) schemes, we propose the best one for each architecture. More specifically, the Asynchronous Island scheme, Island/Master-Slave Hierarchy PGA and Island/Cellular Hierarchy PGA are the best for multi-core, multi-socket multi-core and many-core architectures, respectively. Optimization approaches and rules based on a deep understanding of multi- and many-core architectures are also analyzed and proposed. Finally, the comparison of GA performance on multi-core and many-core architectures are discussed. Three real GA problems are used as benchmarks to evaluate our analysis and findings.There are three extra contributions compared to previous work. Firstly, our findings based on deeply analyzing architectures can be applied to all GA problems, even for other parallel computing, not for a particular GA problem. Secondly, the performance of GAs in our work not only concerns execution speed, also the solution quality has not been considered seriously enough. Thirdly, we propose the theoretical performance and optimization models of PGA on multi-core and many-core architectures, finding a more practical result of the performance comparison of the GA on these architectures, so that the speedup presented in this work is more reasonable and is a better guide to practical decisions. (C) 2013 Elsevier B.V. All rights reserved.
ANTONIO	GA		NO	J	Kroemer, Pavel; Platos, Jan; Snasel, Vaclav	Data Parallel density-based genetic clustering on CUDA Architecture	CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE	2014	Evolutionary clustering algorithms have been proven as a good ability to find clusters in data. Among their advantages belong the abilities to adapt to data and to determine the number of clusters automatically, thus requiring less a priori assumptions about analyzed objects than traditional clustering methods. Unfortunately, such a clustering by genetic algorithms and evolutionary algorithms in general suffers from high computational costs when it comes to recurrent fitness function evaluation. Computing on graphic processing units (GPUs) is a recent programming and development paradigm bringing high performance parallel computing closer to general audience. Modern general purpose GPUs are composed of tens to thousands of computational cores that can execute programs in parallel using the single instruction multiple data parallel processing approach. General purpose GPU programs need to be designed and implemented in a data parallel way and with respect to the architecture of target devices to fully utilize their high performance. This study presents a design, implementation, and evaluation of a data parallel genetic algorithm for density-based clustering. The algorithm was implemented and evaluated on the nVidia Compute Unified Device Architecture (CUDA) platform. Copyright (c) 2013 John Wiley & Sons, Ltd.
ANTONIO	GA	MO, ACO	YES	S	de Souza, Murilo Zangari; Ramirez Pozo, Aurora Trinidad	A GPU Implementation of MOEA/D-ACO for the Multiobjective Traveling Salesman Problem	2014 BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS)	2014	Several Ant Colony Optimization (ACO) algorithms have been proposed to solve multiobjective problems. MOEA/DACO is a multiobjective algorithm based on ACO and the decomposition approach and presents best results when compared with MOEA/D and BiCriterion on discrete optimization problems. This paper proposes a new parallel implementation of MOEA/DACO for execution on the Graphics Processing Unit (GPU) using NVIDIA CUDA in order to improve the efficiency, reaching high quality results in a reasonable execution time. Based on recent researches, both the solution construction and pheromone update phases are implemented using a data parallel approach. We use the multiobjective Traveling Salesman Problem (MTSP) as application. We report speedups of up to 11x from the sequential implementation. Moreover, the results point out that: the number of objectives and the number of subproblems affect directly the speedup.
ANTONIO	GA	MO, ACO	YES	S	Cano, Alberto; Ventura, Sebastian	GPU-Parallel SubTree Interpreter for Genetic Programming	GECCO'14: PROCEEDINGS OF THE 2014 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE	2014	Genetic Programming (GP) is a computationally intensive technique but its nature is embarrassingly parallel. Graphic Processing Units (GPUs) are many-core architectures which have been widely employed to speed up the evaluation of GP. In recent years, many works have shown the high performance and efficiency of GPUs on evaluating both the individuals and the fitness cases in parallel. These approaches are known as population parallel and data parallel. This paper presents a parallel GP interpreter which extends these approaches and adds a new parallelization level based on the concurrent evaluation of the individual's subtrees. A GP individual defined by a tree structure with nodes and branches comprises different depth levels in which there are independent subtrees which can be evaluated concurrently. Threads can cooperate to evaluate different subtrees and share the results via GPU's shared memory. The experimental results show the better performance of the proposal in terms of the GP operations per second (GPops/s) that the GP interpreter is capable of processing, achieving up to 21 billion GPops/s using a NVIDIA 480 GPU. However, some issues raised due to limitations of currently available hardware are to be overcomed by the dynamic parallelization capabilities of the next generation of GPUs.
ANTONIO	GA	EMM	YES	S	Jaros, Jiri; Tyrala, Radek	GPU-accelerated Evolutionary Design of the Complete Exchange Communication on Wormhole Networks	GECCO'14: PROCEEDINGS OF THE 2014 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE	2014	The communication overhead is one of the main challenges in the exascale era, where millions of compute cores are expected to collaborate on solving complex jobs. However, many algorithms will not scale since they require complex global communication and synchronisation. In order to perform the communication as fast as possible, contentions, blocking and deadlock must be avoided. Recently, we have developed an evolutionary tool producing fast and safe communication schedules reaching the lower bound of the theoretical time complexity. Unfortunately, the execution time associated with the evolution process raises up to tens of hours, even when being run on a multi-core processor. In this paper, we propose a revised implementation accelerated by a single Graphic Processing Unit (GPU) delivering speed-up of 5 compared to a quad-core CPU. Subsequently, we introduce an extended version employing up to 8 GPUs in a shared memory environment offering a speed-up of almost 30. This significantly extends the range of interconnection topologies we can cover.
ANTONIO	GA	SNN	YES	S	Carlson, Kristofor D.; Beyeler, Michael; Dutt, Nikil; Krichmar, Jeffrey L.	GPGPU Accelerated Simulation and Parameter Tuning for Neuromorphic Applications	2014 19TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC)	2014	Neuromorphic engineering takes inspiration from biology to design brain-like systems that are extremely low-power, fault-tolerant, and capable of adaptation to complex environments. The design of these artificial nervous systems involves both the development of neuromorphic hardware devices and the development neuromorphic simulation tools. In this paper, we describe a simulation environment that can be used to design, construct, and run spiking neural networks (SNNs) quickly and efficiently using graphics processing units (GPUs). We then explain how the design of the simulation environment utilizes the parallel processing power of GPUs to simulate large-scale SNNs and describe recent modeling experiments performed using the simulator. Finally, we present an automated parameter tuning framework that utilizes the simulation environment and evolutionary algorithms to tune SNNs. We believe the simulation environment and associated parameter tuning framework presented here can accelerate the development of neuromorphic software and hardware applications by making the design, construction, and tuning of SNNs an easier task.
ANTONIO	GA		YES	S	Zhang, Kai; Yang, Siman; Li, Li; Qiu, Ming	Parallel Genetic Algorithm with OpenCL for Traveling Salesman Problem	BIO-INSPIRED COMPUTING - THEORIES AND APPLICATIONS, BIC-TA 2014	2014	In the past few years, CUDA and OpenCL are developed in full use of the GPU, which is a significant topic in high performance computing. In this paper, we have proposed an implementation of the genetic algorithm for the traveling salesman problem on the parallel OpenCL architecture. Population initialization, fitness evaluation, selection, crossover and mutation operators are implemented on the GPU by using individual to thread mapping. Moreover we have evaluated our algorithm using a set of benchmark instances from the TSPLIB library. The comparison results shows that GPU computations provide better performance than traditional CPU implementation.
ANTONIO	GA		YES	S	Krueger, Frederic; Wagner, Daniel; Collet, Pierre	Massively Parallel Generational GA on GPGPU Applied to Power Load Profiles Determination	ARTIFICIAL EVOLUTION, EA 2013	2014	Evolutionary algorithms are capable of solving a wide range of different optimization problems including real world ones. The latter, however, often require a considerable amount of computational power. Parallelization over powerful GPGPU cards is a way to tackle this problem, but this remains hard to do due to their specificities. Parallelizing the fitness function only yields good results if it dwarfs the rest of the evolutionary algorithm. Otherwise, parallelization overhead and Amdahl's law may ruin this effort.In this paper, we will show how completely parallelizing an evolutionary algorithm can help solving a large real world electrical problem with a lightweight evaluation function without quality loss.
ANTONIO	GA		YES	S	Souza, Daniel Leal; Teixeira, Otavio Noura; Monteiro, Dionne Cavalcante; Limao de Oliveira, Roberto Celio; Florenzano Mollinetti, Marco Antonio	A Novel Competitive Quantum-Behaviour Evolutionary Multi-Swarm Optimizer Algorithm Based on CUDA Architecture Applied to Constrained Engineering Design	SWARM INTELLIGENCE, ANTS 2014	2014	This paper presents a new bio-inspired algorithm named Competitive Quantum-Behaviour Evolutionary Multi-Swarm Optimization (CQEMSO) based on CUDA parallel architecture applied to solve engineering problems, using the concept of master/slave swarm working under a competitive scheme and being executed over the paradigm of General Purpose Computing on Graphics Processing Units (GPGPU). The efforts on implementing the CQEMSO algorithm are focused at generating a solution which includes greater quality of search and higher speed of convergence by using mechanisms of evolutionary strategies with the procedures of search and optimization found in the classic QPSO. For performance analysis, the proposed solution was submitted to some well-known engineering problems (WBD, DPV) and its results compared to other solutions found on scientific literature.
ANTONIO	GA	NN	YES	S	Ohkura, Kazuhiro; Yasuda, Toshiyuki; Matsumura, Yoshiyuki; Kadota, Masaki	GPU Implementation of Food-Foraging Problem for Evolutionary Swarm Robotics Systems	SWARM INTELLIGENCE, ANTS 2014	2014	Evolutionary swarm robotics (ESR) is an artificial approach for developing smart collective behavior in a system of homogenous autonomous robots. Robot behavior is generally controlled by evolving artificial neural networks. ESR has been considered a promising approach for swarm robotics systems (SRSs), because swarm behavior naturally emerges from numerous local interactions among the autonomous robots. In contrast, programming individual robots to display appropriate swarm behavior is extremely difficult. However, even in a simulated SRS, ESR is precluded by a very high computational cost. In this study, we introduce a novel implementation that overcomes the computational cost problem. The method employs parallel problem solving on a graphics processing unit (GPU) and OpenMP on a multicore CPU. To demonstrate the efficiency of the proposed method, we engage an evolving SRS in a food-foraging problem.
ANTONIO	GA		YES	J	Zhao Guoliang; Li Yunfei; Wang Chuan	Research on task scheduling in heterogeneous multi-core system	Computer Engineering and Design	2014	To solve the heterogeneous multi-core systems task scheduling problem effectively, a novel hybrid static scheduling algorithm named HSCGS (hybrid successor concerned genetic scheduling) algorithm was proposed. The algorithm was combined with the heuristic and the genetic scheduling algorithm. In the first phase, a heuristic algorithm named SCLS (successor concerned list heuristic scheduling) was proposed to generate a high quality scheduling result. The second phase implemented an improved genetic algorithm (IGA) for scheduling to optimize the scheduling results of the first phase. A dynamic task scheduling algorithm DSCLS (dynamic successor concerned list scheduling) for the heterogeneous multi-core systems was proposed by combining the SCLS algorithm with the schedule engine of the StarPU. The performance of the DSCLS was illustrated by contrast experiments on a heterogeneous computing system consisting of the CPU and the GPU. The experimental results show that for most of the benchmarks, the DSCLS algorithm has significant advantages in both the application execution time and the system throughput.
ANTONIO	GA		YES	S	Nguyen Quang-Hung; Le Thanh Tan; Chiem Thach Phat; Nam Thoai	A GPU-Based Enhanced Genetic Algorithm for Power-Aware Task Scheduling Problem in HPC Cloud	INFORMATION AND COMMUNICATION TECHNOLOGY	2014	In this paper, we consider power-aware task scheduling (PATS) in HPC clouds. Users request virtual machines (VMs) to execute their tasks. Each task is executed on one single VM, and requires a fixed number of cores (i.e., processors), computing power (million instructions per second - MIPS) of each core, a fixed start time and non-preemption in a duration. Each physical machine has maximum capacity resources on processors (cores); each core has limited computing power. The energy consumption of each placement is measured for cost calculating purposes. The power consumption of a physical machine is in a linear relationship with its CPU utilization. We want to minimize the total energy consumption of the placements of tasks. We propose here a genetic algorithm (GA) to solve the PATS problem. The GA is developed with two versions: (1) BKGPUGA, which is an adaptively implemented using NVIDIA's Compute Unified Device Architecture (CUDA) framework; and (2) SGA, which is a serial GA version on CPU. The experimental results show the BKGPUGA program that executed on a single NVIDIA (R) TESLA (TM) M2090 GPU (512 cores) card obtains significant speedups in comparing to the SGA program executing on Intel (R) Xeon (TM) E5-2630 (2.3 GHz) on same input problem size. Both versions share the same GA's parameters (e. g. number of generations, crossover and mutation probability, etc.) and a relative small (10(-11)) on difference of two finesses between BKGPUGA and SGA. Moreover, the proposed BKGPUGA program can handle large-scale task scheduling problems with scalable speedup under limitations of GPU device (e. g. GPU's device memory, number of GPU cores, etc.).
ANTONIO	GA	ACO	YES	J	Wu Shigang; Zhong Cheng	Parallel solving shortest common superstring using genetic algorithm and ant colony optimization	Journal of Computer Applications	2014	According to the capacity of multi-level caches, the population individuality and ant data in CPU main memory were assigned to L3 cache, L2 cache and L1 cache to reduce data transfer overhead among multiple caches during parallel computing. The asynchronous and incomplete transmission was performed between CPU and GPU, and multiple flows were asynchronously executed by multiple GPU kernel functions. The thread number of GPU block was set to the size of 16 times and GPU public memory was divided into bank with the size of 32 times. GPU constant memory was used to store read-only parameters such as cross probability and mutate probability which were read frequently. The read-only big data structure such as string set and overlap matrix were bound to GPU texture memory, and a computation, cache and communication-efficient parallel algorithm for CPU and GPU to coordinate solving shortest common superstring problem was designed and implemented. The experimental results for solving shortest common superstring problem with several sizes show the proposed CPU and GPU parallel algorithm is faster over 70 times than the sequential algorithm.
ANTONIO	GA		NO	S	Padurariu, Florina Roxana; Marinescu, Cristina	NSGA-II: Implementation and Performance Metrics Extraction for CPU and GPU	16TH INTERNATIONAL SYMPOSIUM ON SYMBOLIC AND NUMERIC ALGORITHMS FOR SCIENTIFIC COMPUTING (SYNASC 2014)	2014	Multi-objective Optimization Evolutionary Algorithms are widely employed for solving different real-world optimization problems. Usually their runs involve a considerable amount of time because of the need to evaluate many functions. This particularity makes them good candidates of parallelization. In this work we investigate the benefits of the GPU implementation of the Non-dominated Sorting Genetic Algorithm II (NSGA-II) versus its CPU implementation in terms of the execution time.
ANTONIO	GA	CN	NO	S	Guo, Dongwei; Xing, Hailong; Fu, Fangcai; Liu, Miao	Improvement of Evolution on Evolutionary Set Theory based on Public Goods Game using CUDA	2014 SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT HUMAN-MACHINE SYSTEMS AND CYBERNETICS (IHMSC), VOL 1	2014	This paper introduces an evolutionary model for complex networks on public goods game, which is a dynamical simulation for the real society. The degree distribution of this network is similar to the real society which is closed to Poisson distribution in the first part of process and in accordance with power law distribution in the second. The clustering coefficient of network is enhanced by the cooperator frequency. It is investigated that the cooperator frequency is remarkably promoted by the multiplication factor and initial number of join sets. Moreover, for the simulation of this evolutionary model, the execution on GPUs can achieve speedup over the execution on CPUs.
MARIBEL	GA		NO	J	Hofmann, Johannes; Limmer, Steffen; Fey, Dietmar	Performance investigations of genetic algorithms on graphics cards	SWARM AND EVOLUTIONARY COMPUTATION	2013	Genetic algorithms are one of the most adaptable optimization algorithms. Due to their inherent parallelism they seem well suited for the execution on massively parallel hardware such as graphics processing units. In this paper we put this claim to the test by performing comprehensive experiments. We try to find out how well graphics processing units are suited for the task and what parts of genetic algorithms should be executed on them. We focus especially on the new Fermi generation of Nvidia graphics chips. While it is imperative the fitness function be effectively parallelizable on the GPU, because it is the most computational expensive task of the algorithm, results indicate that if this is the case, speedups of several orders of magnitude are possible compared to conventional multi-core CPUs. Our findings also suggest that, starting with the Fermi architecture, all parts of a genetic algorithm should be carried out on the graphics card instead of only part of it. (C) 2013 Elsevier B.V. All rights reserved.
MARIBEL	GA		YES	J	Yoo, Shin; Harman, Mark; Ur, Shmuel	GPGPU test suite minimisation: search based software engineering performance improvement using graphics cards	EMPIRICAL SOFTWARE ENGINEERING	2013	It has often been claimed that SBSE uses so-called 'embarrassingly parallel' algorithms that will imbue SBSE applications with easy routes to dramatic performance improvements. However, despite recent advances in multicore computation, this claim remains largely theoretical; there are few reports of performance improvements using multicore SBSE. This paper shows how inexpensive General Purpose computing on Graphical Processing Units (GPGPU) can be used to massively parallelise suitably adapted SBSE algorithms, thereby making progress towards cheap, easy and useful SBSE parallelism. The paper presents results for three different algorithms: NSGA2, SPEA2, and the Two Archive Evolutionary Algorithm, all three of which are adapted for multi-objective regression test selection and minimization. The results show that all three algorithms achieved performance improvements up to 25 times, using widely available standard GPUs. We also found that the speed-up was observed to be statistically strongly correlated to the size of the problem instance; as the problem gets harder the performance improvements also get better.
MARIBEL	GA		YES	B	Szenasi, Sandor	GENETIC ALGORITHM FOR PARAMETER OPTIMIZATION OF IMAGE SEGMENTATION ALGORITHM	14TH IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND INFORMATICS (CINTI)	2013	In the current practice of medicine, histopathological examinations are some of the most important tools for clinical diagnoses of a large group of diseases. To help pathologists and to reduce the subjectivity level, it has been proposed that computer-aided procedures be used to provide objective results. The first step of these procedures is the segmentation of the tissue image. In our research, we try to detect nuclei, glands and surface epithelium in Haematoxylin and Eosin ( HE) stained colon tissue samples. This paper focuses on the identification of epithelial cell nuclei.
MARIBEL	GA		NO	B	Cekmez, Ugur; Ozsiginan, Mustafa; Sahingoz, Ozgur Koray	Adapting the GA Approach to Solve Traveling Salesman Problems on CUDA Architecture	14TH IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND INFORMATICS (CINTI)	2013	The vehicle routing problem (VRP) is one of the most challenging combinatorial optimization problems, which has been studied for several decades. The number of solutions for VRP increases exponentially while the number of points, which must be visited increases. There are 3.0x10<^>64 different solutions for 50 visiting points in a direct solution, and it is practically impossible to try out all these permutations. Some approaches like evolutionary algorithms allow finding feasible solutions in an acceptable time. However, if the number of visiting points increases, these algorithms require high performance computing, and they remain insufficient for finding a feasible solution quickly. Graphics Processing Units (GPUs) have tremendous computational power by allowing parallel processing over lots of computing grids, and they can lead to significant performance gains compared with typical CPU implementations. In this paper, it is aimed to present efficient implementation of Genetic Algorithm, which is an evolutionary algorithm that is inspired by processes observed in the biological evolution of living organisms to find approximate solutions for optimization problems such as Traveling Salesman Problem, on GPU. A 1-Thread in 1-Position (1T1P) approach is developed to improve the performance through maximizing efficiency, which then yielded a significant acceleration by using GPUs. Performance of implemented system is measured with the different parameters and the corresponding CPU implementation.
MARIBEL	GA		NO	J	Jin, Zheming; Bakos, Jason D.	Extending the BEAGLE library to a multi-FPGA platform	BMC BIOINFORMATICS	2013	Background: Maximum Likelihood (ML)-based phylogenetic inference using Felsenstein's pruning algorithm is a standard method for estimating the evolutionary relationships amongst a set of species based on DNA sequence data, and is used in popular applications such as RAxML, PHYLIP, GARLI, BEAST, and MrBayes. The Phylogenetic Likelihood Function (PLF) and its associated scaling and normalization steps comprise the computational kernel for these tools. These computations are data intensive but contain fine grain parallelism that can be exploited by coprocessor architectures such as FPGAs and GPUs. A general purpose API called BEAGLE has recently been developed that includes optimized implementations of Felsenstein's pruning algorithm for various data parallel architectures. In this paper, we extend the BEAGLE API to a multiple Field Programmable Gate Array (FPGA)-based platform called the Convey HC-1.Results: The core calculation of our implementation, which includes both the phylogenetic likelihood function (PLF) and the tree likelihood calculation, has an arithmetic intensity of 130 floating-point operations per 64 bytes of I/O, or 2.03 ops/byte. Its performance can thus be calculated as a function of the host platform's peak memory bandwidth and the implementation's memory efficiency, as 2.03 x peak bandwidth x memory efficiency. Our FPGA-based platform has a peak bandwidth of 76.8 GB/s and our implementation achieves a memory efficiency of approximately 50%, which gives an average throughput of 78 Gflops. This represents a similar to 40X speedup when compared with BEAGLE's CPU implementation on a dual Xeon 5520 and 3X speedup versus BEAGLE's GPU implementation on a Tesla T10 GPU for very large data sizes. The power consumption is 92 W, yielding a power efficiency of 1.7 Gflops per Watt.Conclusions: The use of data parallel architectures to achieve high performance for likelihood-based phylogenetic inference requires high memory bandwidth and a design methodology that emphasizes high memory efficiency. To achieve this objective, we integrated 32 pipelined processing elements (PEs) across four FPGAs. For the design of each PE, we developed a specialized synthesis tool to generate a floating-point pipeline with resource and throughput constraints to match the target platform. We have found that using low-latency floating-point operators can significantly reduce FPGA area and still meet timing requirement on the target platform. We found that this design methodology can achieve performance that exceeds that of a GPU-based coprocessor.
MARIBEL	GA		YES	B	Duda, Jerzy; Dlubacz, Wojciech	GPU acceleration for the web browser based evolutionary computing system	2013 17TH INTERNATIONAL CONFERENCE ON SYSTEM THEORY, CONTROL AND COMPUTING (ICSTCC)	2013	This paper presents a novel approach for the acceleration of distributed computing system entirely based on web browsers. We propose two strategies of embedding GPU kernels into the JavaScript code that is run by clients' machines (computing agents) participated in the computing grid, and analyze the speed increase resulting from the application of these methods. The computational experiments are performed on the basis of the two standard optimization problems: a travelling salesman problem and a flowshop scheduling problem. According to the obtained results the calculation of a fitness function accelerated by GPU may bring up to 50% reduction in execution time, while a local search process accelerated by GPU may be reduced tenfold.
MARIBEL	GA		YES	J	Chen Guojun; Liu Yan	Optimization of Road Alignment Using Parallel Genetic Algorithms	Journal of System Simulation	2013	Traditional highway alignment optimization methods are inefficient in interactive highway selection, which can't meet requirement of real-time. A parallel prescreened highway alignment optimization method was proposed. First, highway curve geometric constraints relationship was established according to the vertical and horizontal highway alignment fitting requirements. Then population size was decreased by prescreening non-feasible highway alignments which violate design constraints. The key steps of genetic algorithm, such as population migration, genetic manipulation etc, were decomposed into several independent processes, and the parallel model of each process was implemented with CUDA on GPU accordingly. The results indicate that the proposed method can get a fair good highway alignment with good efficiency.
MARIBEL	GA		NO	S	Paukste, Andrius	Genetic Algorithm on GPU Performance Optimization Issues	INTELLIGENT DATA ENGINEERING AND AUTOMATED LEARNING - IDEAL 2013	2013	The aim of this paper is to investigate genetic algorithm execution on graphics processing unit performance issues and to develop techniques on how to speed up execution by optimizing algorithm execution path and data allocation. The paper presents methods to improve genetic algorithm performance by achieving higher hardware utilization and efficient task distribution between a graphics processing unit and a central processing unit.
MARIBEL	GA		NO	B	Schlueter, Martin; Munetomo, Masaharu	Parallelization Strategies for Evolutionary Algorithms for MINLP	2013 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC)	2013	Two different parallelization strategies for evolutionary algorithms for mixed integer nonlinear programming (MINLP) are discussed and numerically compared in this contribution. The first strategy is to parallelize some internal parts of the evolutionary algorithm. The second strategy is to parallelize the MINLP function calls outside and independently of the evolutionary algorithm. The first strategy is represented here by a genetic algorithm (arGA) for numerical testing. The second strategy is represented by an ant colony optimization algorithm (MIDACO) for numerical testing. It can be shown that the first parallelization strategy represented by arGA is inferior to the serial version of MIDACO, even though if massive parallelization via GPGPU is used. In contrast to this, theoretical and practial tests demonstrate that the parallelization strategy of MIDACO is promising for cpu-time expensive MINLP problems, which often arise in real world applications.
MARIBEL	GA		NO	B	Fujimoto, Noriyuki; Tsutsui, Shigeyoshi	Parallelizing a Genetic Operator for GPUs	2013 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC)	2013	Genetic algorithms (GAs) have parallelism among applications of genetic operators to individuals, but in order to extract high performance of a GPU, parallelizing each genetic operator is desirable. This paper presents parallelization of the OX (order crossover) operator and experimentally show that our parallelized OX is effective on a GPU based on the CUDA architecture. The experiments with an NVIDIA GeForce GTX580 GPU show that our GPU program for the traveling salesman problem (TSP) is about up to 101.3 times faster than the corresponding CPU program on a single core of 2.67 GHz Intel Xeon X5550.
MARIBEL	GA		NO	S	Shao, Chung-Yu; Yu, Tian-Li	Speeding Up Model Building for ECGA on CUDA Platform	GECCO'13: PROCEEDINGS OF THE 2013 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE	2013	Parallelization is a straightforward approach to enhance the efficiency for evolutionary computation due to its inherently parallel nature. Since NVIDIA released the compute unified device architecture (CUDA), graphic processing units have enabled lots of scalable parallel programs in a wide range of fields. However, parallelization of model building for EDAs is rarely studied. In this paper, we propose two implementations on CUDA to speed up the model building in the extended compact genetic algorithm (ECGA). The first implementation is algorithmically identical to original ECGA. Aiming at a greater speed boost, the second implementation modifies the model building. It slightly decreases the accuracy of models in exchange for more speedup. Empirically, the first implementation achieves a speedup of roughly 359 to the baseline on 500-bit trap problem with order 5, and the second implementation achieves a speedup of roughly 506 to the baseline on the same problem. Finally, both of our implementations scale up to 9,800-bit trap problem with order 5 on one single Tesla C2050 GPU card.
MARIBEL	GA		YES	S	Sato, Yuji	Parallelization of Genetic Algorithms and Sustainability on Many-core Processors	PROCEEDINGS OF SEVENTH INTERNATIONAL CONFERENCE ON BIO-INSPIRED COMPUTING: THEORIES AND APPLICATIONS (BIC-TA 2012), VOL 2	2013	In this paper, we study and evaluate fault-tolerant technology for use in the parallel acceleration of evolutionary computation on many-core processors. Specifically, we show running evolutionary computation in parallel on a GPU results in a system that not only performs better as the number of processor cores increases, but is also robust against any physical faults (e.g., stuck-at faults) and transient faults (e.g., faults caused by noise), and makes it less likely that the application program will be interrupted while running. That is, we show that this approach is beneficial for the implementation of systems with sustainability.
MARIBEL	GA		YES	S	Konieczny, Dariusz; Marcinkowski, Maciej; Myszkowski, Pawel B.	GPGPU Implementation of Evolutionary Algorithm for Images Clustering	ADVANCED METHODS FOR COMPUTATIONAL COLLECTIVE INTELLIGENCE	2013	We propose an evolutionary algorithm (EA) usage to image clustering applied to Document Search Engine (DSE). Each document is described by its visual content (including images), preprocessed and clustered by EA. Next, such clusters are core of DSE. However, number of documents and attached images make EA ineffective in such task. Using the natural issue of EA we propose GPGPU (General Purpose Graphic Processing Unit) implementation. The paper describes our proposition, research and results gained in experiments.
MARIBEL	GA		YES	J	Pinel, Frederic; Dorronsoro, Bernabe; Bouvry, Pascal	Solving very large instances of the scheduling of independent tasks problem on the GPU	JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING	2013	In this paper, we present two new parallel algorithms to solve large instances of the scheduling of independent tasks problem. First, we describe a parallel version of the Min-min heuristic. Second, we present GraphCell, an advanced parallel cellular genetic algorithm (CGA) for the CPU. Two new generic recombination operators that take advantage of the massive parallelism of the CPU are proposed for GraphCell. A speedup study shows the high performance of the parallel Min-min algorithm in the CPU versus several CPU versions of the algorithm (both sequential and parallel using multiple threads). GraphCell improves state-of-the-art solutions, especially for larger problems, and it provides an alternative to our CPU Min-min heuristic when more accurate solutions are needed, at the expense of an increased runtime. (C) 2012 Elsevier Inc. All rights reserved.
MARIBEL	GA		YES	S	Shen, Z.; Wang, K.; Wang, F. -Y.	GPU based Non-dominated Sorting Genetic Algorithm-II for Multi-objective Traffic Light Signaling Optimization with Agent Based Modeling	2013 16TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS - (ITSC)	2013	Micro-simulation becomes more and more important in the Intelligent Transportation Systems (ITS) research, because it can provide detailed descriptions of the system. For a multi-agent systems (MAS) modeling of an ITS, the computation burden is large, as it involves the computation of the state changing of all the agents. And, there are many multi-objective optimization problems in the ITS research. In this paper, we solve the traffic light signaling optimization problem and we take the average delay time and the average stop times as two objectives. We use a famous method of Non-dominated Sorting Genetic Algorithm II (NSGA-II). As NSGA-II can be viewed as an intelligent way of running a number of micro-simulations, usually the computation burden is huge. Graphics Processing Units (GPUs) have been a popular tool for parallel computing. The real transportation system runs in parallel and we think that a parallel tool is more suitable for the simulation and optimization of the system. We test GPU based NSGA-II method on a 4 intersection lattice road network, and on the 18 intersection road network of the Zhongguancun area of Beijing. Compared with the CPU version, the GPU version implementation achieves a speedup factor of 21.46 and 27.64 respectively.
PEDRO	GA		YES	S	Zheng, Jinliang; Lu, Jun; Shi, Xinyi; Shi, Yan; Jing, Ruiqing	Motif Recognition Parallel Algorithm based on GPU	2014 INTERNATIONAL CONFERENCE ON CYBER-ENABLED DISTRIBUTED COMPUTING AND KNOWLEDGE DISCOVERY (CYBERC)	2013	In this paper, a GPU-based parallel algorithm is proposed to improve the processing efficiency of motif recognition algorithm. The work includes a serial motif recognition algorithm and a parallel algorithm based on GPU. Our GPU parallel algorithm is compared with the serial algorithm by using of 1 KB promoter data of five kinds of plant genes upstream regions. The experimental results show that a factor of 20 speeds can be achieved. It means that there are a lot of advantages by GPU parallel technology on gene motif recognition algorithm. It is significant to the great amount of data analysis work of genetic sequence.
PEDRO	GA		YES	J	Lin, Juncong; Igarashi, Takeo; Mitani, Jun; Liao, Minghong; He, Ying	A Sketching Interface for Sitting Pose Design in the Virtual Environment	IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS	2012	Character pose design is one of the most fundamental processes in computer graphics authoring. Although there are many research efforts in this field, most existing design tools consider only character body structure, rather than its interaction with the environment. This paper presents an intuitive sketching interface that allows the user to interactively place a 3D human character in a sitting position on a chair. Within our framework, the user sketches the target pose as a 2D stick figure and attaches the selected joints to the environment (e. g., the feet on the ground) with a pin tool. As reconstructing the 3D pose from a 2D stick figure is an ill-posed problem due to many possible solutions, the key idea in our paper is to reduce solution space by considering the interaction between the character and environment and adding physics constraints, such as balance and collision. Further, we formulated this reconstruction into a nonlinear optimization problem and solved it via the genetic algorithm (GA) and the quasi-Newton solver. With the GPU implementation, our system is able to generate the physically correct and visually pleasing pose at an interactive speed. The promising experimental results and user study demonstrates the efficacy of our method.
PEDRO	GA		YES	J	Leung, Chi-Sing; Lam, Ping-Man; Tsang, P. W. M.; Situ, Wuchao	A Graphics Processing Unit Accelerated Genetic Algorithm for Affine Invariant Matching of Broken Contours	JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO TECHNOLOGY	2012	Past research works have demonstrated matching of fragmented contours can be effectively accomplished with the integration of genetic algorithms and migrant principle. Despite the success, the computation involved in the evaluation of the fitness function is substantial. To overcome this problem, a new formulation on the fitness evaluation targeted for graphics processing unit (GPU) has been developed and presented in this paper. Experimental results reveal that the proposed solution is capable of reducing the matching time while maintaining high success rates.
PEDRO	GA		YES	J	Contreras, Ivan; Jiang, Yiyi; Ignacio Hidalgo, J.; Nunez-Letamendia, Laura	Using a GPU-CPU architecture to speed up a GA-based real-time system for trading the stock market	SOFT COMPUTING	2012	The use of mechanical trading systems allows managing a huge amount of data related to the factors affecting investment performance (macroeconomic variables, company information, industrial indicators, market variables, etc.) while avoiding the psychological reactions of traders when they invest in financial markets. When trading is executed in an intra-daily frequency instead a daily frequency, mechanical trading systems needs to be supported by very powerful engines since the amount of data to deal with grow while the response time required to support trades gets shorter. Numerous studies document the use of genetic algorithms (GAs) as the engine driving mechanical trading systems. The empirical insights provided in this paper demonstrate that the combine use of GA together with a GPU-CPU architecture speeds up enormously the power and search capacity of the GA for this kind of financial applications. Moreover, the parallelization allows us to implement and test previous GA approximations. Regarding the investment results, we can report 870% of profit for the S&P 500 companies in a 10-year time period (1996-2006), when the average profit of the S&P 500 in the same period was 273%.
PEDRO	GA		NO	J	Maitre, Ogier; Krueger, Frederic; Querry, Stephane; Lachiche, Nicolas; Collet, Pierre	EASEA: specification and execution of evolutionary algorithms on GPGPU	SOFT COMPUTING	2012	EASEA is a framework designed to help non-expert programmers to optimize their problems by evolutionary computation. It allows to generate code targeted for standard CPU architectures, GPGPU-equipped machines as well as distributed memory clusters. In this paper, EASEA is presented by its underlying algorithms and by some example problems. Achievable speedups are also shown onto different NVIDIA GPGPUs cards for different optimization algorithm families.
PEDRO	GA		NO	S	Kroemer, Pavel; Platos, Jan; Snasel, Vaclav	Genetic Algorithm for Clustering Accelerated by the CUDA Platform	PROCEEDINGS 2012 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS (SMC)	2012	Unsupervised clustering of large data sets is a complicated NP-hard task. Due to its complexity, various meta-heuristic machine learning algorithms have been used to automate or aid the clustering process. Genetic and evolutionary algorithms have been deployed to find clusters in data sets with success. However, also evolutionary clustering suffers from the high computational demands when it comes to fitness function evaluation. The GPU computing is a recent programming and development paradigm introducing high performance parallel computing to general audience. This work presents an initial design and implementation of a genetic algorithm for density based clustering on the GPU using the nVidia CUDA platform.
PEDRO	GA		YES	S	Ouyang, Xuchang; Kwoh, Chee Keong	GPU Accelerated Molecular Docking with Parallel Genetic Algorithm	PROCEEDINGS OF THE 2012 IEEE 18TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED SYSTEMS (ICPADS 2012)	2012	Molecular docking is a widely used tool in Computer-aided Drug Design and Discovery. Due to the complexity of simulating the chemical events when two molecules interact, highly accelerated molecular docking programs are of great interest and importance for practical use. In this paper, we present a GPU accelerated docking program implemented with CUDA. The hardware-enabled texture interpolation is employed for fast energy evaluation. Two types of parallel genetic algorithms are mapped to the CUDA computing architecture and used for the search of optimal docking result. Comparing to the CPU implementation, the GPU accelerated docking program achieved significant speedup while producing comparable results to the CPU version. The source code is made public at http://code.google.com/p/cudock/.
PEDRO	GA		YES	S	Chan, Lau Mai; Srinivasan, Rajagopalan	A Graphic Processing Unit (GPU) Algorithm for Improved Variable Selection in Multivariate Process Monitoring	11TH INTERNATIONAL SYMPOSIUM ON PROCESS SYSTEMS ENGINEERING, PTS A AND B	2012	Process monitoring is extremely important for producing high quality product and at the same time ensuring safe working environment in chemical process industry. Recently, it has been shown that selection of an appropriate subset of variables can improve the monitoring performance. The main contribution of this work is the development of a parallel version of the Genetic Algorithm-Principal Component Analysis algorithm which was proposed by Ghosh et al. [2] for variable selection. The developed algorithm has been implemented using NVIDIA's Compute Unified Device Architecture, CUDA parallel computing platform. Experimental results show that the proposed parallel approach is 12 times faster than the original serial code when applied to the Tennessee Eastman challenge problem.
PEDRO	GA	?	NO	S	Pedemonte, Martin; Alba, Enrique; Luna, Francisco	Towards the Design of Systolic Genetic Search	2012 IEEE 26TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS & PHD FORUM (IPDPSW)	2012	This paper elaborates on a new, fresh parallel optimization algorithm specially engineered to run on Graphic Processing Units (GPUs). The undelying operation relates to Systolic Computation. The algorithm, called Systolic Genetic Search (SGS) is based on the synchronous circulation of solutions through a grid of processing units and tries to profit from the parallel architecture of GPUs. The proposed model has shown to outperform a random search and two genetic algorithms for solving the Knapsack Problem over a set of increasingly sized instances. Additionally, the parallel implementation of SGS on a GeForce GTX 480 graphics processing unit (GPU), obtaining a runtime reduction up to 35 times.
PEDRO	GA		YES	S	Lucas, Drew; Crane, Carl, III	Development of a Multi-resolution Parallel Genetic Algorithm for Autonomous Robotic Path Planning	2012 12TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS)	2012	Deterministic algorithms such as A* and D* have been applied with great success to autonomous robotic path planning. However, as search space size increases numerous problem domains will likely become intractable when reactive behavior is desired. This is extremely relevant when considering the exponential increase in search space sizes due to any linear addition of degrees of freedom. Over the last few decades, Evolutionary Algorithms (EA) have been shown to be particularly applicable to extremely large search spaces. However, it is often assumed that generational convergence is the only measure of quality for an EA. A novel combination of the Anytime Planning (AP) criteria with multi-resolution search spaces is explored for application to high-level semi-reactive path planning. Separate populations are evolved in parallel within different abstractions of the search space while low cost solutions from each population are exchanged among the populations. Generational evaluations in low-resolution search spaces can be evaluated quickly generating seed candidate solutions that are likely to speed convergence in the high-resolution search spaces. Convergence rates up to 4x were achieved along with modest decreases in path cost. Parallel GPU computation was then applied to allow reactive searching up to 40Hz in search grids up to 8192x8192 cells.
PEDRO	GA		YES	S	Kroemer, Pavel; Platos, Jan; Snasel, Vaclav	Evolutionary Clustering on CUDA	20TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE (ECAI 2012)	2012	Unsupervised clustering of large data sets is a complicated task. Due to its complexity, various meta-heuristic machine learning algorithms have been used to automate the clustering process. Genetic and evolutionary algorithms have been deployed to find clusters in data sets with success. The GPU computing is a recent programming paradigm introducing high performance parallel computing to general audience. This work presents an acceleration of a genetic algorithm for density based clustering on the GPU using the nVidia compute unified device architecture (CUDA).
PEDRO	GA		YES	J	Ben-Shalom, Roy; Aviv, Amit; Razon, Benjamin; Korngreen, Alon	Optimizing ion channel models using a parallel genetic algorithm on graphical processors	JOURNAL OF NEUROSCIENCE METHODS	2012	"We have recently shown that we can semi-automatically constrain models of voltage-gated ion channels by combining a stochastic search algorithm with ionic currents measured using multiple voltage-clamp protocols. Although numerically successful, this approach is highly demanding computationally, with optimization on a high performance Linux cluster typically lasting several days. To solve this computational bottleneck we converted our optimization algorithm for work on a graphical processing unit (GPU) using NVIDIA's CUDA. Parallelizing the process on a Fermi graphic computing engine from NVIDIA increased the speed similar to 180 times over an application running on an 80 node Linux cluster, considerably reducing simulation times. This application allows users to optimize models for ion channel kinetics on a single, inexpensive, desktop ""super computer,"" greatly reducing the time and cost of building models relevant to neuronal physiology. We also demonstrate that the point of algorithm parallelization is crucial to its performance. We substantially reduced computing time by solving the ODEs (Ordinary Differential Equations) so as to massively reduce memory transfers to and from the GPU. This approach may be applied to speed up other data intensive applications requiring iterative solutions of ODEs. (C) 2012 Elsevier B.V. All rights reserved."
GUSTAVO	GA		no	S	Prata, Paula; Fazendeiro, Paulo; Sequeira, Pedro; Padole, Chandrashekhar	A Comment on Bio-inspired Optimisation via GPU Architecture: The Genetic Algorithm Workload	SWARM, EVOLUTIONARY, AND MEMETIC COMPUTING, (SEMCCO 2012)	2012	This paper characterizes a genetic algorithm based on the analysis of the workload of its operators. Different granular parallel implementations of a genetic algorithm in the GPU architecture are compared against the correspondent sequential version. With the help of three benchmark problems, a complete characterization of the relative execution times of the genetic operators, varying the population cardinality and the genotype size, is offered. The best speedups, obtained with large populations, are higher than one thousand times faster than the corresponding sequential version. The assessment of different granularity levels shows that the two-dimensional parallelism supported by the GPU architecture is valuable for the crossover operator.
GUSTAVO	GA		yes	S	Fazendeiro, Paulo; Padole, Chandrashekhar; Sequeira, Pedro; Prata, Paula	OpenCL Implementations of a Genetic Algorithm for Feature Selection in Periocular Biometric Recognition	SWARM, EVOLUTIONARY, AND MEMETIC COMPUTING, (SEMCCO 2012)	2012	This paper explores OpenCL implementations of a genetic algorithm used to optimize the features vector in periocular biometric recognition. Using a multi core platform the algorithm is tested for CPU and GPU, exploring different parallelization levels for each operator of the genetic algorithm. The results show that using the GPU platform it is possible to accelerate the algorithm by several orders of magnitude, with a recognition rate similar to the one obtained in the sequential version. The results also show that it is possible to use only a small portion of the features without any degradation of the classifier's recognition rate.
GUSTAVO	GA		yes	J	Gomez-Pulido, Juan A.; Vega-Rodriguez, Miguel A.; Sanchez-Perez, Juan M.; Priem-Mendes, Silvio; Carreira, Vitor	Accelerating floating-point fitness functions in evolutionary algorithms: a FPGA-CPU-GPU performance comparison	GENETIC PROGRAMMING AND EVOLVABLE MACHINES	2011	Many large combinatorial optimization problems tackled with evolutionary algorithms often require very high computational times, usually due to the fitness evaluation. This fact forces programmers to use clusters of computers, a computational solution very useful for running applications of intensive calculus but having a high acquisition price and operation cost, mainly due to the Central Processing Unit (CPU) power consumption and refrigeration devices. A low-cost and high-performance alternative comes from reconfigurable computing, a hardware technology based on Field Programmable Gate Array devices (FPGAs). The main objective of the work presented in this paper is to compare implementations on FPGAs and CPUs of different fitness functions in evolutionary algorithms in order to study the performance of the floating-point arithmetic in FPGAs and CPUs that is often present in the optimization problems tackled by these algorithms. We have taken advantage of the parallelism at chip-level of FPGAs pursuing the acceleration of the fitness functions (and consequently, of the evolutionary algorithms) and showing the parallel scalability to reach low cost, low power and high performance computational solutions based on FPGA. Finally, the recent popularity of GPUs as computational units has moved us to introduce these devices in our performance comparisons. We analyze performance in terms of computation times and economic cost.
GUSTAVO	GA		yes	J	Sanci, Seckin; Isler, Veysi	A Parallel Algorithm for UAV Flight Route Planning on GPU	INTERNATIONAL JOURNAL OF PARALLEL PROGRAMMING	2011	Aerial surveillance missions require a geographical region known as the area of interest to be inspected. The route that the aerial reconnaissance vehicle will follow is known as the flight route. Flight route planning operation has to be done before the actual mission is executed. A flight route may consist of hundreds of pre-defined geographical positions called waypoints. The optimal flight route planning manages to find a tour passing through all of the waypoints by covering the minimum possible distance. Due to the combinatorial nature of the problem it is impractical to devise a solution using brute force approaches. This study presents an approach to find a near-optimal solution to the flight route planning problem. The proposed approach is based on converting the problem into Traveling Salesman Problem which is solved using Genetic Algorithms on Graphical Processing Unit (GPU). The parallel genetic algorithm devised for GPUs has been compared to the alternative algorithms and found to be promising in terms of speed-up. We also present a thorough analysis of the implemented algorithm for several cases using different parameter values.
GUSTAVO	GA		yes	S	Yamamoto, Lidia; Banzhaf, Wolfgang; Collet, Pierre	Evolving Reaction-Diffusion Systems on GPU	PROGRESS IN ARTIFICIAL INTELLIGENCE	2011	Reaction-diffusion systems contribute to various morphogenetic processes, and can also be used as computation models in real and artificial chemistries. Evolving reaction-diffusion solutions automatically is interesting because it is otherwise difficult to engineer them to achieve a target pattern or to perform a desired task. However most of the existing work focuses on the optimization of parameters of a fixed reaction network. in this paper we extend this state of the art by also exploring the space of alternative reaction networks, with the help of GPU hardware. We compare parameter optimization and reaction network optimization on the evolution of reaction-diffusion solutions leading to simple spot patterns. Our results indicate that these two optimization modes tend to exhibit qualitatively different evolutionary dynamics: in the former, the fitness tends to improve continuously in gentle slopes, while the latter tends to exhibit large periods of stagnation followed by sudden jumps, a sign of punctuated equilibria.
GUSTAVO	GA		yes	S	Potti, Subbaraj; Pothiraj, Sivakumar	GPGPU Implementation of Parallel Memetic Algorithm for VLSI Floorplanning Problem	TRENDS IN COMPUTER SCIENCE, ENGINEERING AND INFORMATION TECHNOLOGY	2011	The VLSI Physical design floorplanning is the process where circuit description is converted into geometric description. This NP-Optimization problem with non-slicing blocks is very hard to solve. Memetic algorithms are used to solve NP-Optimization problems. Memetic algorithms are a family of meta-heuristic search algorithms in which a rule-based representation of Local Search (LS) is co-adapted alongside the candidate solutions within a hybrid evolutionary system. However, they may execute for a long time for difficult problems, because of several fitness evaluations. A promising approach to overcome this limitation is to parallelize these algorithms. In this paper, we propose to implement a parallel Memetic Algorithm (MA) on Graphical Processing Units. The General Purpose Graphical Processing Unit (GPGPU) is the complete parallel hardware which is best used for the Parallel Computing. The Parallel Memetic Algorithm we followed for an application perspective is a modified or hybrid genetic algorithm with extensive attributes to local search. The Parallel Memetic Algorithm operator gives a perfect exploration in the available search area and it is typical for addressing a modular assignment problem. It reduces the time efficiently for execution which is a boon for VLSI industry where we don't have to spend more weeks for Physical design to be completed. We perform experiments to compare our parallel MA with an ordinary MA and demonstrate that the former is much more effective than the latter. Both fitness evaluation and genetic operations are spread over the GPU cores, allowing for the efficient processing of very large datasets. The parallel nature of Memetic algorithm can be best harnessed with help of GPGPU and significant changes in execution time and optimization are shown for VLSI Floorplanning problem.
GUSTAVO	GA		yes	S	Thuy Tuong Nguyen; Jeon, Jae Wook	Real-Time Background Compensation for PTZ Cameras Using GPU Accelerated and Range-Limited Genetic Algorithm Search	ADVANCES IN IMAGE AND VIDEO TECHNOLOGY, PT I	2011	We propose a range-limited Genetic Algorithm (GA) search with an accelerated Graphics Processing Unit (GPU) based implementation for background compensation where pan-tilt-zoom (PTZ) cameras are used. Our method contains GA with search ranges restricted using histogram matching and GPU implementation of the range-limited GA. First, based on histogram matching, estimation of approximate scale (camera zoom) and translation (camera pan and tilt) parameters is used to restrict the ranges for the later GA search. Next, the GA is applied to find an optimal solution. Experimental comparisons of the proposed method to existing methods show that our work has advantages: robust to critical situations due to using GA, and fast processing.
GUSTAVO	GA	PSA	no	S	Cardenas-Montes, Miguel; Vega-Rodriguez, Miguel A.; Jose Rodriguez-Vazquez, Juan; Gomez-Iglesias, Antonio	Effect of the Block Occupancy in GPGPU over the Performance of Particle Swarm Algorithm	ADAPTIVE AND NATURAL COMPUTING ALGORITHMS, PT I	2011	Diverse technologies have been used to accelerate the execution of Evolutionary Algorithms. Nowadays, the GPGPU cards have demonstrated a high efficiency in the improvement of the execution times in a wide range of scientific problems, including some excellent examples with diverse categories of Evolutionary Algorithms. Nevertheless, the studies in depth of the efficiency of each one of these technologies, and how they affect to the final performance are still scarce. These studies are relevant in order to reduce the execution time budget, and therefore affront higher dimensional problems. In this work, the improvement of the speed-up face to the percentage of threads used per block in the GPGPU card is analysed. The results conclude that a correct election of the occupancy-number of the threads per block-contributes to win an additional speed-up.
GUSTAVO	GA		yes	S	Shen, Zhen; Wang, Kai; Zhu, Fenghua	Agent-based Traffic Simulation and Traffic Signal Timing Optimization with GPU	2011 14TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC)	2011	"With the advantage of simulating the details of a transportation system, the ""microsimulation"" of a traffic system has long been a hot topic in the Intelligent Transportation Systems (ITS) research. The Cellular Automata (CA) and the Multi-Agent System (MAS) modeling are two typical methods for the traffic microsimulation. However, the computing burden for the microsimulation and the optimization based on it is usually very heavy. In recent years the Graphics Processing Units (GPUs) have been applied successfully in many areas for parallel computing. Compared with the traditional CPU cluster, GPU has an obvious advantage of low cost of hardware and electricity consumption. In this paper we build an MAS model for a road network of four signalized intersections and we use a Genetic Algorithm (GA) to optimize the traffic signal timing with the objective of maximizing the number of the vehicles leaving the network in a given period of time. Both the simulation and the optimization are accelerated by GPU and a speedup by a factor of 195 is obtained. In the future we will extend the work to large scale road networks."
GUSTAVO	GA		yes	S	Pecero, Johnatan E.; Pinel, Frederic; Dorronsoro, Bernabe; Danoy, Gregoire; Bouvry, Pascal; Zomaya, Albert Y.	Efficient Hierarchical Task Scheduling on GRIDS Accounting for Computation and Communications	INTELLIGENT DECISION SYSTEMS IN LARGE-SCALE DISTRIBUTED ENVIRONMENTS	2011	This chapter proposes a novel Grid-based scheduling algorithm that optimizes both computation and communications costs of workflow applications. Based on a hierarchical two-steps optimization process, a super scheduler first applies a Recursive Convex Clustering Algorithm (RCCA) that efficiently clusters tasks while minimizing communication costs. In the second step, a resource-broker assigns the generated convex sets to resources clusters. Local schedulers then optimize the makespan for the group of tasks assigned to their cluster, using a graphic processing unit (GPU)-based parallel cellular Genetic Algorithm (cGA). The performance improvement brought by this novel two-step scheduling algorithm compared to a hierarchical list-scheduling approach is empirically demonstrated on different real-world workflow applications.
GUSTAVO	GA		no	J	Zhu, Weihang; Yaseen, Ashraf; Li, Yaohang	DEMCMC-GPU: An Efficient Multi-Objective Optimization Method with GPU Acceleration on the Fermi Architecture	NEW GENERATION COMPUTING	2011	In this paper, we present an efficient method implemented on Graphics Processing Unit (GPU), DEMCMC-CPU, for multi-objective continuous optimization problems. The DEMCMC-GPU kernel is the DEMCMC algorithm, which combines the attractive features of Differential Evolution (DE) and Markov Chain Monte Carlo (MCMC) to evolve a population of Markov chains toward a diversified set of solutions at the Pareto optimal front in the multi-objective search space. With parallel evolution of a population of Markov chains, the DEMCMC algorithm is a. natural fit for the CPU architecture. The implementation of DEMCMC-CPU on the pre-Fermi architecture can lead to a (similar to)25 speedup on a set of multi-objective benchmark function problems, compare to the CPU-only implementation of DEMONIC. By taking advantage of new cache mechanism in the emerging NVIDIA Fermi CPU architecture, efficient sorting algorithm on CPU, and efficient parallel pseudorandom number generators; the speedup of DEMCMC-GPU can be aggressively improved to (similar to)100.
GUSTAVO	GA		no	S	Fujimoto, Noriyuki; Tsutsui, Shigeyoshi	A Highly-Parallel TSP Solver for a GPU Computing Platform	NUMERICAL METHODS AND APPLICATIONS	2011	The traveling salesman problem (TSP) is probably the most, widely studied combinatorial optimization problem and has become! a standard testbed for new algorithmic ideas. Recently the use of it CPU (Graphics Processing Unit) to accelerate non-graphics computations has attracted much attention due to its high performance and low cost. This paper presents a novel method to solve TSP with a GPC based on the CUDA architecture. The proposed method highly parallelizes a serial metaheuristic algorithm which is a genetic algorithm with the OX (order crossover) operator and the 2-opt local search. The experiments with an NVIDIA CePorce GTX285 GPU and a single core of 3.0 GHz Intel Core2 Duo E6850 CPU show that (air GPU: implementation is about up to 24.2 times faster than the corresponding CPU implementation.
GUSTAVO	GA		no	S	Guillen, A.; van Heeswijk, M.; Sovilj, D.; Arenas, M. G.; Herrera, L. J.; Pomares, H.; Rojas, I.	Variable Selection in a GPU Cluster Using Delta Test	Advances in Computational Intelligence, IWANN 2011, Pt I	2011	The work presented in this paper consists in an adaptation of a Genetic Algorithm (GA) to perform variable selection in an heterogeneous cluster where the nodes are themselves clusters of GPUs. Due to this heterogeneity, several mechanisms to perform a load balance will be discussed as well as the optimization of the fitness function to take advantage of the GPUs available. The algorithm will be compared with previous parallel implementations analysing the advantages and disadvantages of the approach, showing that for large data sets, the proposed approach is the only one that can provide a solution.
GUSTAVO	GA		yes	S	Arenas, M. G.; Mora, A. M.; Romero, G.; Castillo, P. A.	GPU Computation in Bioinspired Algorithms: A Review	Advances in Computational Intelligence, IWANN 2011, Pt I	2011	Bioinspired methods usually need a high amount of computational resources. For this reason, parallelization is an interesting alternative in order to decrease the execution time and to provide accurate results. In this sense, recently there has been a growing interest in developing parallel algorithms using graphic processing units (GPU) also refered as GPU computation. Advances in the video gaming industry have led to the production of low-cost, high-performance graphics processing units (GPUs) that possess more memory bandwidth and computational capability than central processing units (CPUs). As GPUs are available in personal computers, and they are easy to use and manage through several GPU programming languages (CUDA, OpenCL, etc.), graphics engines are being adopted widely in scientific computing applications, particularly in the fields of computational biology and bioinformatics. This paper reviews the use of GPUs to solve scientific problems, giving an overview of current software systems.
GUSTAVO	GA		yes	S	Fontanarosa, Joel B; Dai, Yang	An evolutionary optimization strategy using graphics processing units to efficiently investigate gene-gene interactions in genetic association studies.	Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual Conference	2011	The analysis of gene-gene interactions related to common complex human diseases is complicated by the increasing scale of genetic association analysis. Concurrent with the advances in genetic technology that led to these large data sets, improvements have been made in parallel computing with graphics processing units (GPUs). The data-intensive nature of genetic association analysis makes this problem particularly suitable for improved computation with the powerful computing resources available in GPUs. In this study, we present a GPU-accelerated discrete optimization strategy to improve the computational efficiency of multi-locus association analysis. We implemented an adaptive evolutionary algorithm that takes advantage of linkage disequilibrium to reduce the need for exhaustive search for combinations of genetic markers. The proposed GPU algorithm was shown to have improved efficiency and equivalent power relative to the CPU version.
GUSTAVO	GA		no	S	Prata, Paula; Fazendeiro, Paulo; Sequeira, Pedro	Towards Cost-Effective Bio-inspired Optimization: A Prospective Study on the GPU Architecture	SWARM, EVOLUTIONARY, AND MEMETIC COMPUTING, PT II	2011	This paper studies the impact of varying the population's size and the problem's dimensionality in a parallel implementation, for an NVIDIA GPU, of a canonical GA. The results show that there is an effective gain in the data parallel model provided by modern GPU's and enhanced by high level languages such as OpenCL. In the reported experiments it was possible to obtain a speedup higher than 140 thousand times for a population's size of 262 144 individuals.
GUSTAVO	GA		no	J	Rouhipour, Marjan; Bentley, Peter J.; Shayani, Hooman	Fast bio-inspired computation using a GPU-based systemic computer	PARALLEL COMPUTING	2010	Biology is inherently parallel. Models of biological systems and bio-inspired algorithms also share this parallelism, although most are simulated on serial computers. Previous work created the systemic computer - a new model of computation designed to exploit many natural properties observed in biological systems, including parallelism. The approach has been proven through two existing implementations and many biological models and visualizations. However to date the systemic computer implementations have all been sequential simulations that do not exploit the true potential of the model. In this paper the first ever parallel implementation of systemic computation is introduced. The CPU Systemic Computation Architecture is the first implementation that enables parallel systemic computation by exploiting the multiple cores available in graphics processors. Comparisons with the serial implementation when running two programs at different scales show that as the number of systems increases, the parallel architecture is several hundred times faster than the existing implementations, making it feasible to investigate systemic models of more complex biological systems. (C) 2010 Elsevier B.V. All rights reserved.
GUSTAVO	GA		no	J	Hu, Ting; Harding, Simon; Banzhaf, Wolfgang	Variable population size and evolution acceleration: a case study with a parallel evolutionary algorithm	GENETIC PROGRAMMING AND EVOLVABLE MACHINES	2010	With current developments of parallel and distributed computing, evolutionary algorithms have benefited considerably from parallelization techniques. Besides improved computation efficiency, parallelization may bring about innovation to many aspects of evolutionary algorithms. In this article, we focus on the effect of variable population size on accelerating evolution in the context of a parallel evolutionary algorithm. In nature it is observed that dramatic variations of population size have considerable impact on evolution. Interestingly, the property of variable population size here arises implicitly and naturally from the algorithm rather than through intentional design. To investigate the effect of variable population size in such a parallel algorithm, evolution dynamics, including fitness progression and population diversity variation, are analyzed. Further, this parallel algorithm is compared to a conventional fixed-population-size genetic algorithm. We observe that the dramatic changes in population size allow evolution to accelerate.
GUSTAVO	GA		yes	S	Pospichal, Petr; Schwarz, Josef; Jaros, Jiri	PARALLEL GENETIC ALGORITHM SOLVING 0/1 KNAPSACK PROBLEM RUNNING ON THE GPU	16TH INTERNATIONAL CONFERENCE ON SOFT COMPUTING MENDEL 2010	2010	In this work, we show that consumer-level $100 CPU can be used to significantly speed-up optimization of 0/1 Knapsack problem. We identify strong and weak points of CPU architecture and propose our parallel genetic algorithm model implemented in CUDA running entirely on the CPU. We show that CPU must be utilized for sufficiently long time in order to obtain reasonable program speedup. Then we compare results quality and speed of our model with single-threaded CPU code implemented using Galib. Peak speedup of CPU GA execution performance is 1340x resp. 134x for 4-bit resp. 40-bit problem instances while maintaining reasonable results quality.
GUSTAVO	GA		yes	S	Ebner, Marc	Evolving Object Detectors with a GPU Accelerated Vision System	EVOLVABLE SYSTEMS: FROM BIOLOGY TO HARDWARE	2010	Using CPU processing, it is now possible to develop an evolutionary vision system working at interactive frame rates. Our system uses motion as an important cue to evolve detectors which are able to detect an object when this cue is not available. Object detectors consist of a series of high level operators which are applied to the input image. A matrix of low level point operators are used to recombine the output of the high level operators. With this contribution, we investigate, which image processing operators are most useful for object detection. It was found that the set of image processing operators could be considerably reduced without reducing recognition performance. Reducing the set of operators lead to an increase in speedup compared to a standard CPU implementation.
GUSTAVO	GA		yes	S	Rouhipour, Marjan; Bentley, Peter J.; Shayani, Hooman	Systemic Computation Using Graphics Processors	EVOLVABLE SYSTEMS: FROM BIOLOGY TO HARDWARE	2010	Previous work created the systemic computer a model of computation designed to exploit many natural properties observed in biological systems, including parallelism. The approach has been proven through two existing implementations and many biological models and visualizations. However to date the systemic computer implementations have all been sequential simulations that do not exploit the true potential of the model. In this paper the first parallel implementation of systemic computation is introduced. The GPU Systemic Computation Architecture is the first implementation that enables parallel systemic computation by exploiting multiple cores available in graphics processors. Comparisons with the serial implementation when running a genetic algorithm at different scales show that as the number of systems increases, the parallel architecture is several hundred times faster than the existing implementations, making it feasible to investigate systemic models of more complex biological systems.
PABLO	GA		YES	J	Park, In Kyu; 안일준	Design of Omok AI using Genetic Algorithm and Game Trees and Their Parallel Processing on the GPU	Journal of KIISE : Computer Systems and Theory	2010	This paper proposes an efficient method for design and implementation of the artificial intelligence (AI) of ‘omok’ game on the GPU. The proposed AI is designed on a cooperative structure using min-max game tree and genetic algorithm. Since the evaluation function needs intensive computation but is independently performed on a lot of candidates in the solution space, it is computed on the GPU in a massive parallel way. The implementation on NVIDIA CUDA and the experimental results show that it outperforms significantly over the CPU, in which parallel game tree and genetic algorithm on the GPU runs more than 400 times and 300 times faster than on the CPU. In the proposed cooperative AI, selective search using genetic algorithm is performed subsequently after the full search using game tree to search the solution space more efficiently as well as to avoid the thread overflow. Experimental results show that the proposed algorithm enhances the AI significantly and makes it run within the time limit given by the game's rule.
PABLO	GA		NO	S	Vidal, Pablo; Alba, Enrique	Cellular Genetic Algorithm on Graphic Processing Units	NICSO 2010: NATURE INSPIRED COOPERATIVE STRATEGIES FOR OPTIMIZATION	2010	The availability of low cost powerful parallel graphic cards has estimulated a trend to implement diverse algorithms on Graphic Processing Units (GPUs). In this paper we describe the design of a parallel Cellular Genetic Algorithm (cGA) on a GPU and then evaluate its performance. Beyond the existing works on master-slave for fitness evaluation, we here implement a cGA exploiting data and instructions parallelism at the population level. Using the CUDA language on a GTX-285 CPU hardware, we show how a cGA can profit from it to create an algorithm of improved physical efficiency and numerical efficacy with respect to a CPU implementation. Our approach stores individuals and their fitness values in the global memory of the CPU. Both, fitness evaluation and genetic operators are implemented entirely on GPU (i.e. no CPU is used). The presented approach allows us benefit from the numerical advantages of cGAs and the efficiency of a low-cost hut powerful platform.
PABLO	GA		NO	S	Sharma, Deepak; Collet, Pierre	GPGPU-Compatible Archive Based Stochastic Ranking Evolutionary Algorithm (G-ASREA) for Multi-Objective Optimization	PARALLEL PROBLEM SOLVING FROM NATURE-PPSN XI, PT II	2010	In this paper, a GPGPU (general purpose graphics processing unit) compatible Archived based Stochastic Ranking Evolutionary Algorithm (G-ASREA) is proposed, that ranks the population with respect to an archive of non-dominated solutions. It reduces the complexity of the deterministic ranking operator from O(mn(2)) to O(man)(star) and further speeds up ranking on GPU.Experiments compare G-ASREA with a CPU version of ASREA and NSGA-II on ZDT test functions for a wide range of population sizes. The results confirm the gain in ranking complexity by showing that on 10K individuals, G-ASREA ranking is approximate to x5000 faster than NSGA-II and approximate to x15 faster than ASREA.
PABLO	GA		YES	S	Steflen, Peter; Giegerich, Robert; Giraud, Mathieu	GPU Parallelization of Algebraic Dynamic Programming	PARALLEL PROCESSING AND APPLIED MATHEMATICS, PART II	2010	Algebraic Dynamic Programming (ADP) is a framework to encode a broad range of optimization problems, including common bioinformatics problems like RNA folding or pairwise sequence alignment The ADP complier translates such ADP programs into C As all the ADP problems have similar data dependencies in the dynamic programming tables a genetic parallelization is possible We updated the compiler to include a parallel backend launching a large number of independent threads Depending on the application, we report speedups ranging from 6.1 x to 25.8 x on a Nvidia GTX 280 through the CUDA libraries
PABLO	GA		YES	J	Munawar, Asim; Wahib, Mohamed; Munetomo, Masaharu; Akama, Kiyoshi	Hybrid of genetic algorithm and local search to solve MAX-SAT problem using nVidia CUDA framework	GENETIC PROGRAMMING AND EVOLVABLE MACHINES	2009	General Purpose computing over Graphical Processing Units (GPGPUs) is a huge shift of paradigm in parallel computing that promises a dramatic increase in performance. But GPGPUs also bring an unprecedented level of complexity in algorithmic design and software development. In this paper we describe the challenges and design choices involved in parallelizing a hybrid of Genetic Algorithm (GA) and Local Search (LS) to solve MAXimum SATisfiability (MAX-SAT) problem on a state-of-the-art nVidia Tesla GPU using nVidia Compute Unified Device Architecture (CUDA). MAX-SAT is a problem of practical importance and is often solved by employing metaheuristics based search methods like GAs and hybrid of GA with LS. Almost all the parallel GAs (pGAs) designed in the last two decades were designed for either clusters or MPPs. Unfortunately, very little research is done on the implementation of such algorithms over commodity graphics hardware. GAs in their simple form are not suitable for implementation over the Single Instruction Multiple Thread (SIMT) architecture of a GPU, and the same is the case with conventional LS algorithms. In this paper we explore different genetic operators that can be used for an efficient implementation of GAs over nVidia GPUs. We also design and introduce new techniques/operators for an efficient implementation of GAs and LS over such architectures. We use nVidia Tesla C1060 to perform several numerical tests and performance measurements and show that in the best case we obtain a speedup of 25x. We also discuss the effects of different optimization techniques on the overall execution time.
PABLO	GA		YES	J	Robilliard, Denis; Marion-Poty, Virginie; Fonlupt, Cyril	Genetic programming on graphics processing units	GENETIC PROGRAMMING AND EVOLVABLE MACHINES	2009	The availability of low cost powerful parallel graphics cards has stimulated the port of Genetic Programming (GP) on Graphics Processing Units (GPUs). Our work focuses on the possibilities offered by Nvidia G80 GPUs when programmed in the CUDA language. In a first work we have showed that this setup allows to develop fine grain parallelization schemes to evaluate several GP programs in parallel, while obtaining speedups for usual training sets and program sizes. Here we present another parallelization scheme and optimizations about program representation and use of GPU fast memory. This increases the computation speed about three times faster, up to 4 billion GP operations per second. The code has been developed within the well known ECJ library and is open source.
PABLO	GA	ML	YES	J	Fuchs, Raphael; Waser, Juergen; Groeller, Meister Eduard	Visual Human plus Machine Learning	IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS	2009	In this paper we describe a novel method to integrate interactive visual analysis and machine learning to support the insight generation of the user. The suggested approach combines the vast search and processing power of the computer with the superior reasoning and pattern recognition capabilities of the human user. An evolutionary search algorithm has been adapted to assist in the fuzzy logic formalization of hypotheses that aim at explaining features inside multivariate, volumetric data. Up to now, users solely rely on their knowledge and expertise when looking for explanatory theories. However, it often remains unclear whether the selected attribute ranges represent the real explanation for the feature of interest. Other selections hidden in the large number of data variables could potentially lead to similar features. Moreover, as simulation complexity grows, users are confronted with huge multidimensional data sets making it almost impossible to find meaningful hypotheses at all. We propose an interactive cycle of knowledge-based analysis and automatic hypothesis generation. Starting from initial hypotheses, created with linking and brushing, the user steers a heuristic search algorithm to look for alternative or related hypotheses. The results are analyzed in information visualization views that are linked to the volume rendering. Individual properties as well as global aggregates are visually presented to provide insight into the most relevant aspects of the generated hypotheses. This novel approach becomes computationally feasible due to a GPU implementation of the time-critical parts in the algorithm. A thorough evaluation of search times and noise sensitivity as well as a case study on data from the automotive domain substantiate the usefulness of the suggested approach.
PABLO	GA		NO	B	Zaloudek, Ludek; Sekanina, Lukas; Simek, Vaclav	GPU Accelerators for Evolvable Cellular Automata	2009 COMPUTATION WORLD: FUTURE COMPUTING, SERVICE COMPUTATION, COGNITIVE, ADAPTIVE, CONTENT, PATTERNS	2009	In order to design cellular automata rules by means of evolutionary algorithms, high computational demands need to be met. This problem may be partially solved by parallelization. Since parallel supercomputers and server clusters are expensive and often overburdened, this paper proposes the evolution of cellular automata rules on small and inexpensive graphic processing units. The main objective of this paper is not to evolve any actual cellular automata but to demonstrate that evolution of cellular automata rules can be accelerated significantly using graphics processing units. Several methods of speeding-up the evolution of cellular automata rules are proposed, evaluated and compared, some with very good results.
PABLO	GA		NO	S	Maitre, Ogier; Lachiche, Nicolas; Clauss, Philippe; Baumes, Laurent; Corma, Avelino; Collet, Pierre	Efficient Parallel Implementation of Evolutionary Algorithms on GPGPU Cards	EURO-PAR 2009: PARALLEL PROCESSING, PROCEEDINGS	2009	"A parallel solution to the implementation of evolutionary algorithms is proposed; where the most; costly part of the whole evolutionary algorithm computations (the population evaluation), is deported to a GPGPU card. Experiments are presented for two benchmark examples on two models of GPGPU cards: first a ""toy"" problem is used to illustrate some noticable behaviour characteristics before a real problem is tested out. Results show a speed-up of up to 100 times compared to an execution on a standard micro-processor. To our knowledge; this solution is the first showing such an efficiency with GPGPU cards. Finally, the EASEA language and its compiler are also extended to allow users to easily specify and generate efficient parallel implementations of evolutionay algorithms using GPGPU cards."
PABLO	GA		NO	S	Wong, Man Leung; Wong, Tien Tsin	Implementation of Parallel Genetic Algorithms on Graphics Processing Units	INTELLIGENT AND EVOLUTIONARY SYSTEMS	2009	In this paper, we propose to parallelize a Hybrid Genetic Algorithm (HGA) on Graphics Processing Units (GPUs) which are available and installed on ubiquitous personal computers. HGA extends the classical genetic algorithm by incorporating the Cauchy mutation operator from evolutionary programming. In our parallel HGA, all steps except the random number generation procedure are performed in GPU and thus our parallel HGA can be executed effectively and efficiently. We suggest and develop the novel pseudo-deterministic selection method which is comparable to the traditional global selection approach with significant execution time performance advantages. We perform experiments to compare our parallel HGA with our previous parallel FEP (Fast Evolutionary programming) and demonstrate that the former is much more effective and efficient than the latter. The parallel and sequential implementations of HGA are compared in a number of experiments, it is observed that the former outperforms the latter significantly. The effectiveness and efficiency of the pseudo-deterministic selection method is also studied.
PABLO	GA		YES	J	Nie, Dong-Hu; Han, Kyu-Phil; Lee, Heng-Suk	GPU-based Stereo Matching Algorithm with the Strategy of Population-based Incremental Learning	Journal of Information Processing Systems	2009	To solve the general problems surrounding the application of genetic algorithms in stereo matching, two measures are proposed. Firstly, the strategy of simplified population-based incremental learning (PBIL) is adopted to reduce the problems with memory consumption and search inefficiency， and a scheme for controlling the distance of neighbors for disparity smoothness is inserted to obtain a wide-area consistency of disparities. In addition, an alternative version of the proposed algorithm, without the use of a probability vector, is also presented for simpler set-ups. Secondly, programmable graphics-hardware (GPU) consists of multiple multi-processors and has a powerful parallelism which can perform operations in parallel at low cost. Therefore, in order to decrease the running time further, a model of the proposed algorithm, which can be run on programmable graphics-hardware (GPU), is presented for the first time. The algorithms are implemented on the CPU as well as on the GPU and are evaluated by experiments. The experimental results show that the proposed algorithm offers better performance than traditional BMA methods with a deliberate relaxation and its modified version in terms of both running speed and stability. The comparison of computation times for the algorithm both on the GPU and the CPU shows that the former has more speed-up than the latter, the bigger the image size is.
PABLO	GA		NO	J	LI Jianming; CHI Zhongxian; WAN Danling	Parallel genetic algorithm based on fine-grained model with GPU-accelerated	Control and Decision	2008	An algorithm based on GPU(graphics processing unit) acceleration fine-grained parallel genetic algorithm(PGA) is proposed to improve the performance of genetic algorithm for application to large-scale problems and multivariable solutions. The process of parallel genetic algorithms is converted into that of texture-rendering based on GPU, which maks PGA greatly accelerated in it. The experimental results show that the algorithm inhibits the phenomenon of premature efficiently, increases the particle population in the PGA, speeds up its running and provides ordinary user with a feasible PGA solution.
PABLO	GA		YES	B	Franke, Tobias; Jung, Yvonne	Real-time mixed reality with GPU techniques	GRAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS	2008	In this paper, we propose a combination of modem GPU-based methods that are able to generate high-quality, interactive real-time rendering for augmented and mixed reality applications. We also present a new approach to estimate surface reflection functions and materials from images using genetic algorithms.
PABLO	GA		NO	B	Li, Jian-Ming; Wang, Xiao-Jing; He, Rong-Sheng; Chi, Zhong-Xian	An efficient fine-grained parallel genetic algorithm based on GPU-accelerated	2007 IFIP INTERNATIONAL CONFERENCE ON NETWORK AND PARALLEL COMPUTING WORKSHOPS, PROCEEDINGS	2007	Fine-grained parallel genetic algorithm (FGPGA), though a popular and robust strategy for solving complicated optimization problems, is sometimes inconvenient to use as its population size is restricted by heavy data communication and the parallel computers are relatively difficult to use, manage, maintain and may not be accessible to most researchers. In this paper, we propose a FGPGA method based on GPU-acceleration, which maps parallel GA algorithm to texture-rendering on consumer-level graphics cards. The analytical results demonstrate that the proposed method increases the population size, speeds up its execution and provides ordinary users with a feasible FGPGA solution.
PABLO	GA		NO	B	Wong, Man-Leung; Wong, Tien-Tsin	Parallel hybrid genetic algorithms on consumer-level graphics hardware	2006 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION, VOLS 1-6	2006	In this paper, we report a parallel Hybrid Genetic Algorithm (HGA) on consumer-level graphics cards. HGA extends the classical genetic algorithm by incorporating the Cauchy mutation operator from evolutionary programming. In our parallel HGA, all steps except the random number generation procedure are performed in Graphics Processing Unit (GPU) and thus our parallel HGA can be executed effectively and efficiently. We propose the pseudo-deterministic selection method which is comparable to the traditional global selection approach with significant execution time performance advantages. We perform experiments to compare our parallel HGA with our previous parallel FEP (Fast Evolutionary programming) and demonstrate that the former is much more effective and efficient than the latter. The parallel and sequential implementations of HGA are compared in a number of experiments, it is observed that the former outperforms the latter significantly. The effectiveness and efficiency of the pseudodeterministic selection method is also studied.
PABLO	GA		YES	B	Kaul, Karsten; Bohn, Christian-A.	A Genetic Texture Packing Algorithm on a Graphical Processing Unit	9TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND ARTIFICIAL INTELLIGENCE	2006	"Interactively modeled virtual scenes usually contain hundreds of single separate textures. A common task to prepare these scenes for real-time rendering is to compile the set of many textures into one large texture which is better suited to be handled by modern graphics hardware.We present an approach for accomplishing the above task automatically. First, a patchwork of near-optimal compactness is calculated through a genetic algorithm (GA), second - since ""GA are slow"" - we implement the genetic algorithm on a CPU and show that it easily outperforms a standard CPU implementation."
PABLO	GA		NO	B	Luo, ZW; Yang, ZP; Liu, HZ; Lv, WX	GA computation of 3-SAT problem on graphic process unit	Progress in Intelligence Computation & Applications	2005	3-SAT problem is an NP-hard problem. Using genetic algorithm can make it easy to solve, but usually still need high performance computing. Recently, with the rapid development on graphics processing unit (GPLT), it opens another possibility to do high performance computing. In this paper, we explore how commodity available graphics card can be applied to soft computing problems, such as genetic algorithm. We develop a GA program based on graphic hardware to solve MAT problem. Using this program, we show that GPU can be used as a general purpose processor. Comparing the speed of our graphics hardware implementations to standard CPU implementations, we demonstrate performance improvements possibility. We also give some possibility to improve the efficiency. Based on our results and current trends in the development of GPU, we believe that graphics hardware will widely used in general purpose computing, and there will be more progress in the use of graphic hardware to the area of soft computing. As a hardware speedup method, commodity hardware will become increasingly important to high-performance computing.
PABLO	GA		YES	S	Withayachumnankul, W; Laksanapanai, B; Pintavirooj, C	Hardware-accelerated objective function evaluation for medical image registration	TENCON 2004 - 2004 IEEE REGION 10 CONFERENCE, VOLS A-D, PROCEEDINGS: ANALOG AND DIGITAL TECHNIQUES IN ELECTRICAL ENGINEERING	2004	Generally, image registration using genetic algorithm is a time-consuming process since the algorithm needs to evaluate the objective function several hundred times depending on the vastness of search space. The situation appears worse if the registration is intensity-based due to the interpolation loops prior to each objective function. However, with the availability of modern graphic processing unit (GPU) one can take an advantage from interpolating division normally used to interpolate the texels for 2D-texture mapping. Issued via OpenGL API, the image interpolation requires half time less than it ever does without losing of accuracy.
GUSTAVO	ES		no	S	Brandejsky, Tomas	SUDGESTION FOR EVOLUTIONARY STRATEGY IMPLEMENTATION IN CUDA	16TH INTERNATIONAL CONFERENCE ON SOFT COMPUTING MENDEL 2010	2010	Nowadays, there exist cheap source of significant computation power - GPGPU (General Purpose computation on Graphics Processing Unit). Unfortunately, many implementations of GAs (Genetic Algorithms) and Evolutionary Strategies on GPGPUs Allow implementations on general purpose CPUs and they are not so efficient as they might be. The paper discusses differences between standard CPUs, parallel systems based on CPUs (e.g. multi-kernel CPUs) and GPGPUs. Then, the main approaches to GPGPU programming are studied and novel implementation of Evolutionary Strategy is presented.
JJ	GP		YES	J	da Silva, Cleomar Pereira; Dias, Douglas Mota; Bentes, Cristiana; Cavalcanti Pacheco, Marco Aurelio	Use of graphics processing units for automatic synthesis of programs	COMPUTERS & ELECTRICAL ENGINEERING	2015	Genetic programming (GP) is an evolutionary method that allows computers to solve problems automatically. However, the computational power required for the evaluation of billions of programs imposes a serious limitation on the problem size. This work focuses on accelerating GP to support the synthesis of large problems. This is done by completely exploiting the highly parallel environment of graphics processing units (GPUs). Here, we propose a new quantum-inspired linear GP approach that implements all the GP steps in the GPU and provides the following: (1) significant performance improvements in the GP steps, (2) elimination of the overhead of copying the fitness results from the GPU to the CPU, and (3) incorporation of a new selection mechanism-to recognize the programs with the best evaluations. The proposed approach outperforms the previous approach for large-scale synthetic and real-world problems. Further, it provides a remarkable speedup over the CPU execution. (C) 2015 Elsevier Ltd. All rights reserved.
JJ	GP		YES	J	Cano, Alberto; Zafra, Amelia; Ventura, Sebastian	Speeding up multiple instance learning classification rules on GPUs	KNOWLEDGE AND INFORMATION SYSTEMS	2015	Multiple instance learning is a challenging task in supervised learning and data mining. However, algorithm performance becomes slow when learning from large-scale and high-dimensional data sets. Graphics processing units (GPUs) are being used for reducing computing time of algorithms. This paper presents an implementation of the G3P-MI algorithm on GPUs for solving multiple instance problems using classification rules. The GPU model proposed is distributable to multiple GPUs, seeking for its scalability across large-scale and high-dimensional data sets. The proposal is compared to the multi-threaded CPU algorithm with streaming SIMD extensions parallelism over a series of data sets. Experimental results report that the computation time can be significantly reduced and its scalability improved. Specifically, an speedup of up to 149 can be achieved over the multi-threaded CPU algorithm when using four GPUs, and the rules interpreter achieves great efficiency and runs over 108 billion genetic programming operations per second.
JJ	GP		YES	J	da Silva, Cleomar Pereira; Dias, Douglas Mota; Bentes, Cristiana; Cavalcanti Pacheco, Marco Aurelio; Cupertino, Leandro Fontoura	Evolving GPU Machine Code	JOURNAL OF MACHINE LEARNING RESEARCH	2015	Parallel Graphics Processing Unit (GPU) implementations of GP have appeared in the literature using three main methodologies: (i) compilation, which generates the individuals in GPU code and requires compilation; (ii) pseudo-assembly, which generates the individuals in an intermediary assembly code and also requires compilation; and (iii) interpretation, which interprets the codes. This paper proposes a new methodology that uses the concepts of quantum computing and directly handles the GPU machine code instructions. Our methodology utilizes a probabilistic representation of an individual to improve the global search capability. In addition, the evolution in machine code eliminates both the overhead of compiling the code and the cost of parsing the program during evaluation. We obtained up to 2.74 trillion GP operations per second for the 20-bit Boolean Multiplexer benchmark. We also compared our approach with the other three GPU-based acceleration methodologies implemented for quantum-inspired linear GP. Significant gains in performance were obtained.
JJ	GP		YES	S	Langdon, William B.; Lam, Brian Yee Hong; Petke, Justyna; Harman, Mark	Improving CUDA DNA Analysis Software with Genetic Programming	GECCO'15: PROCEEDINGS OF THE 2015 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE	2015	We genetically improve BarraCUDA using a BNF grammar incorporating C scoping rules with GP. Barracuda maps next generation DNA sequences to the human genome using the Burrows-Wheeler algorithm (BWA) on nVidia Tesla parallel graphics hardware (GPUs). GI using phenotypic tabu search with manually grown code can graft new features giving more than 100 fold speed up on a performance critical kernel without loss of accuracy.
JJ	GP		YES	S	Ha, Sungjoo; Moon, Byung-Ro	Fast Knowledge Discovery in Time Series with GPGPU on Genetic Programming	GECCO'15: PROCEEDINGS OF THE 2015 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE	2015	We tackle the problem of knowledge discovery in time series data using genetic programming and GPGPUs. Using genetic programming, various precursor patterns that have certain attractive qualities are evolved to predict the events of interest. Unfortunately, evolving a set of diverse patterns typically takes huge execution time, sometimes longer than one month for this case. In this paper, we address this problem by proposing a parallel GP framework using GPGPUs, particularly in the context of big financial data. By maximally exploiting the structure of the nVidia GPGPU platform on stock market time series data, we were able see more than 250-fold reduction in the running time.
ANTONIO	GP		YES	J	Lu, Shufang; Mok, P. Y.; Jin, Xiaogang	From design methodology to evolutionary design: An interactive creation of marble-like textile patterns	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE	2014	In this paper, by the integration of design methodology theories with evolutionary computation, a new design system is developed to evolve preferred designs on complex marbling patterns using interactive 'perceptual selection'. The system is formulated in a way to assist the productive-deductive-inductive design reasoning process of the users. Therefore, complex mathematical functions do not cognitively overload the designers, who are released for more critical tasks of aesthetic assessment and new design rules induction. With the implementation on a graphics-processing unit (GPU), real-time complex marbling patterns can be created by the system. The system encourages creativity in the design process and accelerates new design generation. In addition, the resulting patterns fulfil the textile industry requirements of repeat and can be output as vector images. (c) 2014 Elsevier Ltd. All rights reserved.
ANTONIO	GP		YES	S	Langdon, William B.; Modat, Marc; Petke, Justyna; Harman, Mark	Improving 3D Medical Image Registration CUDA Software with Genetic Programming	GECCO'14: PROCEEDINGS OF THE 2014 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE	2014	Genetic Improvement (GI) is shown to optimise, in some cases by more than 35%, a critical component of healthcare industry software across a diverse range of six nVidia graphics processing units (GPUs). GP and other search based software engineering techniques can automatically optimise the current rate limiting CUDA parallel function in the Nifty Reg open source C++ project used to align or register high resolution nuclear magnetic resonance NMRI and other diagnostic NIfTI images. Future Neurosurgery techniques will require hardware acceleration, such as GPGPU, to enable real time comparison of three dimensional in theatre images with earlier patient images and reference data. With millimetre resolution brain scan measurements comprising more than ten million voxels the modified kernel can process in excess of 3 billion active voxels per second.
ANTONIO	GP		YES	S	Hidalgo, J. Ignacio; Colmenar, J. Manuel; Risco-Martin, Jose L.; Sanchez-Lacruz, Carlos; Lanchares, Juan; Garnica, Oscar	Solving GA-Hard Problems with EMMRS and GPGPUs	GECCO'14: PROCEEDINGS OF THE 2014 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE	2014	Different techniques have been proposed to tackle GA-Hard problems. Some techniques work with different encodings and representations, other use reordering operators and several, such as the Evolutionary Mapping Method (EMM), apply genotype-phenotype mappings. EMM uses multiple chromosomes in a single cell for mating with another cell within a single population. Although EMM gave good results, it fails on solving some deceptive problems. In this line, EMMRS (EMM with Replacement and Shift) adds a new operator, consisting on doing a replacement and a shift of some of the bits within the chromosome. Results showed the efficiency of the proposal on deceptive problems. However, EMMRS was not tested with other kind of hard problems. In this paper we have adapted EMMRS for solving the Traveling Salesman Problem (TSP). The encodings and genetic operators for solving the TSP are quite different to those applied on deceptive problems. In addition, execution times recommended the parallelization of the GA. We implemented a GPU parallel version. We present here some preliminary results proving that Evolutionary Mapping Method with Replacement and Shift gives good results not only in terms of quality but also in terms of speedup on its GPU parallel version for some instances of the TSP problem.
ANTONIO	GP		YES	S	Langdon, William B.	Genetic Improvement of Programs	16TH INTERNATIONAL SYMPOSIUM ON SYMBOLIC AND NUMERIC ALGORITHMS FOR SCIENTIFIC COMPUTING (SYNASC 2014)	2014	Genetic programming can optimise software, including: evolving test benchmarks, generating hyper-heuristics by searching meta-heuristics, generating communication protocols, composing telephony systems and web services, generating improved hashing and C++ heap managers, redundant programming and even automatic bug fixing. Particularly in embedded real-time or mobile systems, there may be many ways to trade off expenses (such as time, memory, energy, power consumption) vs. functionality. Human programmers cannot try them all. Also the best multi-objective Pareto trade off may change with time, underlying hardware and network connection or user behaviour. It may be GP can automatically suggest different trade offs for each new market. Recent results include substantial speed up by evolving a new version of a program customised for a special case.
MARIBEL	GP		YES	J	Romero-Vivas, Eduardo; Von Borstel, Fernando D.; Villa-Medina, Isaac	Analysis of Genetic Expression with Microarrays using GPU Implemented Algorithms	Computación y Sistemas	2013	DNA microarrays are used to simultaneously analyze the expression level of thousands of genes under multiple conditions; however, massive amount of data is generated making its analysis a challenge and an ideal candidate for massive parallel processing. Among the available technologies, the use of General Purpose computation on Graphics Processing Units (GPGPU) is an efficient cost-effective alternative, compared to a Central Processing Unit (CPU). This paper presents an implementation of algorithms using Compute Unified Device Architecture (CUDA) to determine statistical significance in the evaluation of gene expression levels for a microarray hybridization experiment designed and carried out at the Centro de Investigaciones Biológicas del Noroeste S.C. (CIBNOR). The obtained results are compared to traditional implementations.
MARIBEL	GP		NO	J	Vitola, Jaime; Sanabria, Adriana; Pedraza, Cesar; Sepulveda, Johanna	Parallel algorithm for evolvable-based boolean synthesis on GPUs	ANALOG INTEGRATED CIRCUITS AND SIGNAL PROCESSING	2013	The use of evolutionary algorithms in the boolean synthesis is an attractive alternative to generate interesting and efficient hardware structures, with a high computational load. This paper presents the implementation of a parallel genetic programming (PGP) for boolean synthesis on a GPU-CPU based platform. Our implementation uses the island model, that allows the parallel and independent evolution of the PGP through the multiple processing units of the GPU and the multiple cores of a new generation desktop processors. We tested multiple mapping alternatives of the PGP on the platform in order to optimize the PGP response time. As a result we show that our approach achieves a speedup up to 41 compared to CPU implementation.
MARIBEL	GP		YES	S	Wu, Chih-Hung; Chiang, Chin-Yuan; Chen, Yi-Han	Parallelism of Evolutionary Design of Image Filters for Evolvable Hardware Using GPU	2013 14TH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD 2013)	2013	Evolvable Hardware (EHW) is a combination of evolutionary algorithm and reconfigurable hardware devices. Due to its flexible and adaptive ability, EHW-based solutions receive a lot of attention in industrial applications. One of the obstacles to realize an EHW-based method is its very long training time. This study deals with the parallelism of EHW-based design of image filters using graphic processing units (GPUs). The design process is analyzed and decomposed into some smaller processes that can run in parallel. Pixel-based data for training and verifying EHW solutions are partitioned according to the architecture of GPU. Several strategies for deploying parallel processes are developed and implemented. With the proposed method, significant improvements on the efficiency of training EHW models are gained. Using a GPU with 240 cores, a speedup of 64 times is obtained. This paper evaluates and compares the performance of the proposed method with other ones.
MARIBEL	GP		YES	J	Augusto, Douglas A.; Barbosa, Helio J. C.	Accelerated parallel genetic programming tree evaluation with OpenCL	JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING	2013	"Inspired by the process of natural selection, genetic programming (GP) aims at automatically building arbitrarily complex computer programs. Being classified as an ""embarrassingly"" parallel technique, GP can theoretically scale up to tackle very diverse problems by increasingly adding computational power to its arsenal. With today's availability of many powerful parallel architectures, a challenge is to take advantage of all those heterogeneous compute devices in a portable and uniform way. This work proposes both (i) a transcription of existing GP parallelization strategies into the OpenCL programming platform; and (ii) a freely available implementation to evaluate its suitability for GP, by assessing the performance of parallel strategies on the CPU and CPU processors from different vendors. Benchmarks on the symbolic regression and data classification domains were performed. On the CPU we could achieve 13 billion node evaluations per second, delivering almost 10 times the throughput of a twelve-core CPU. (C) 2012 Elsevier Inc. All rights reserved."
PEDRO	GP		NO	J	Chitty, Darren M.	Fast parallel genetic programming: multi-core CPU versus many-core GPU	SOFT COMPUTING	2012	Genetic Programming (GP) is a computationally intensive technique which is also highly parallel in nature. In recent years, significant performance improvements have been achieved over a standard GP CPU-based approach by harnessing the parallel computational power of many-core graphics cards which have hundreds of processing cores. This enables both fitness cases and candidate solutions to be evaluated in parallel. However, this paper will demonstrate that by fully exploiting a multi-core CPU, similar performance gains can also be achieved. This paper will present a new GP model which demonstrates greater efficiency whilst also exploiting the cache memory. Furthermore, the model presented in this paper will utilise Streaming SIMD Extensions to gain further performance improvements. A parallel version of the GP model is also presented which optimises multiple thread execution and cache memory. The results presented will demonstrate that a multi-core CPU implementation of GP can yield performance levels that match and exceed those of the latest graphics card implementations of GP. Indeed, a performance gain of up to 420-fold over standard GP is demonstrated and a threefold gain over a graphics card implementation.
PEDRO	GP		YES	J	Cano, Alberto; Zafra, Amelia; Ventura, Sebastian	Speeding up the evaluation phase of GP classification algorithms on GPUs	SOFT COMPUTING	2012	The efficiency of evolutionary algorithms has become a studied problem since it is one of the major weaknesses in these algorithms. Specifically, when these algorithms are employed for the classification task, the computational time required by them grows excessively as the problem complexity increases. This paper proposes an efficient scalable and massively parallel evaluation model using the NVIDIA CUDA GPU programming model to speed up the fitness calculation phase and greatly reduce the computational time. Experimental results show that our model significantly reduces the computational time compared to the sequential approach, reaching a speedup of up to 820x. Moreover, the model is able to scale to multiple GPU devices and can be easily extended to any evolutionary algorithm.
PEDRO	GP		YES	J	McKenney, Dave; White, Tony	Stock trading strategy creation using GP on GPU	SOFT COMPUTING	2012	This paper investigates the speed improvements available when using a graphics processing unit (GPU) for evaluation of individuals in a genetic programming (GP) environment. An existing GP system is modified to enable parallel evaluation of individuals on a GPU device. Several issues related to implementing GP on GPU are discussed, including how to perform tree-based GP on a device without recursion support, as well as the effect that proper memory layout can have on speed increases when using CUDA-enabled nVidia GPU devices. The specific GP implementation is designed to evolve stock trading strategies using technical analysis indicators. The second goal of this research is to investigate the possible improvement in performance when training individuals on a larger number of stocks and training days. This increased training size (nearly 100,000 training points) is enabled due to the speedups realized by GPU evaluation. Several different scenarios were used to test various speed optimizations of GP evaluation on the GPU device, with a peak speedup factor of over 600 (when compared to sequential evaluation on a 2.4 GHz CPU). Also, it is found that increasing the number of stocks and the length of the training period can result in higher out-of-training testing profitability.
PEDRO	GP		NO	S	Shao, Shuai; Liu, Xiyang; Zhou, Mingyuan; Zhan, Jiguo; Liu, Xin; Chu, Yanli; Chen, Hao	A GPU-based Implementation of an Enhanced GEP Algorithm	PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE	2012	Gene expression programming (GEP) is a functional genotype/phenotype system. The separation scheme increases the efficiency and reliability of GEP. However, the computational cost increases considerably with the expansion of the scale of problems. In this paper, we introduce a GPU-accelerated hybrid variant of GEP named pGEP (parallel GEP). In order to find the optimal constant coefficients locally on the fixed function structure, the Method of Least Square (MLS) has been embedded into the GEP evolutionary process. We tested pGEP using a broad problem set with a varying number of instances. In the performance experiment, the GPU-based GEP, when compared with the traditional GEP version, increased speeds by approximately 250 times. We compared pGEP with other well-known constant creation methods in terms of accuracy, demonstrating MLS performs at several orders of magnitude higher in terms of both the best residuals and average residuals.
GUSTAVO	GP		yes	J	Langdon, W. B.	Graphics processing units and genetic programming: an overview	SOFT COMPUTING	2011	A top end graphics card (GPU) plus a suitable SIMD interpreter can deliver a several hundred fold speed up, yet cost less than the computer holding it. We give highlights of AI and computational intelligence applications in the new field of general purpose computing on graphics hardware (GPGPU). In particular, we surveyed genetic programming (GP) use with GPU. We gave several applications from Bioinformatics and showed that how the fastest GP is based on an interpreter rather than compilation. Finally using GP to generate GPU CUDA kernel C++ code is sketched.
GUSTAVO	GP		yes	J	Wilson, Garnett; Banzhaf, Wolfgang	Deployment of parallel linear genetic programming using GPUs on PC and video game console platforms	GENETIC PROGRAMMING AND EVOLVABLE MACHINES	2010	"We present a general method for deploying parallel linear genetic programming (LGP) to the PC and Xbox 360 video game console by using a publicly available common framework for the devices called XNA (for ""XNA's Not Acronymed""). By constructing the LGP within this framework, we effectively produce an LGP ""game"" for PC and XBox 360 that displays results as they evolve. We use the GPU of each device to parallelize fitness evaluation and the mutation operator of the LGP algorithm, thus providing a general LGP implementation suitable for parallel computation on heterogeneous devices. While parallel GP implementations on PCs are now common, both the implementation of GP on a video game console using GPU and the construction of a GP around a framework for heterogeneous devices are novel contributions. The objective of this work is to describe how to implement the parallel execution of LGP in order to use the underlying hardware (especially GPU) on the different platforms while still maintaining loyalty to the general methodology of the LGP algorithm built for the common framework. We discuss the implementation of texture-based data structures and the sequential and parallel algorithms built for their use on both CPU and GPU. Following the description of the general algorithm, the particular tailoring of the implementations for each hardware platform is described. Sequential (CPU) and parallel (GPU-based) algorithm performance is compared on both PC and video game platforms using the metrics of GP operations per second, actual time elapsed, speedup of parallel over sequential implementation, and percentage of execution time used by the GPU versus CPU."
GUSTAVO	GP		no	J	Whigham, Peter A.; Dick, Grant	Implicitly Controlling Bloat in Genetic Programming	IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION	2010	During the evolution of solutions using genetic programming (GP) there is generally an increase in average tree size without a corresponding increase in fitness-a phenomenon commonly referred to as bloat. Although previously studied from theoretical and practical viewpoints there has been little progress in deriving controls for bloat which do not explicitly refer to tree size. Here, the use of spatial population structure in combination with local elitist replacement is shown to reduce bloat without a subsequent loss of performance. Theoretical concepts regarding inbreeding and the role of elitism are used to support the described approach. The proposed system behavior is confirmed via extensive computer simulations on benchmark problems. The main practical result is that by placing a population on a torus, with selection defined by a Moore neighborhood and local elitist replacement, bloat can be substantially reduced without compromising performance.
GUSTAVO	GP		yes	S	Ebner, Marc	Towards Automated Learning of Object Detectors	APPLICATIONS OF EVOLUTIONARY COMPUTATION, PT I, PROCEEDINGS	2010	Recognizing arbitrary objects in images or video sequences is a difficult task for a computer vision system. We work towards automated learning of object detectors from video sequences (without user interaction). Our system uses object motion as an important cue to detect independently moving objects in the input sequence. The largest object is always taken as the teaching input, i.e. the object to be extracted. We use Cartesian Genetic Programming to evolve image processing routines which deliver the maximum output at the same position where the detected object is located. The graphics processor (GPU) is used to speed up the image processing. Our system is a step towards automated learning of object detectors.
GUSTAVO	GP		no	S	Langdon, W. B.	A Many Threaded CUDA Interpreter for Genetic Programming	GENETIC PROGRAMMING, PROCEEDINGS	2010	A Single Instruction Multiple Thread CUDA interpreter provides SIMD like parallel evaluation of the whole GP population of million reverse polish notation (RPN) expressions on graphics cards and nVidia Tesla. Using sub-machine code tree GP a sustain peak performance of 665 billion GP operations per second (10,000 speed up) and an average of 22 peta GP ops per day is reported for a single GPU card on a Boolean induction benchmark never attempted before, let alone solved.
GUSTAVO	GP		no	S	Maitre, Ogier; Lachiche, Nicolas; Collet, Pierre	Fast Evaluation of GP Trees on GPGPU by Optimizing Hardware Scheduling	GENETIC PROGRAMMING, PROCEEDINGS	2010	This paper shows that it is possible to use General Purpose Graphic Processing Unit cards for a. fast evaluation of different Genetic Programming trees on as few as 32 fitness cases by using the hardware scheduling of NVIDIA cards. Depending on the function set, observed speedup ranges between x50 and x250 on one half of an NVidia GTX295 GPGPU card, vs a single core of an Intel Quad core Q8200.
PABLO	GP	ML	YES	S	Cano, Alberto; Zafra, Amelia; Ventura, Sebastian	Solving Classification Problems Using Genetic Programming Algorithms on GPUs	HYBRID ARTIFICIAL INTELLIGENCE SYSTEMS, PT 2	2010	Genetic Programming is very efficient in problem solving compared to other proposals but its performance is very slow when the size of the data increases. This paper proposes a model for multi-threaded Genetic Programming classification evaluation using a NVIDIA CUDA GPUs programming model to parallelize the evaluation phase and reduce computational time. Three different well-known Genetic Programming classification algorithms are evaluated using the parallel evaluation model proposed. Experimental results using UCI Machine Learning data sets compare the performance of the three classification algorithms in single and multithreaded Java, C and CUDA GPU code. Results show that our proposal is much more efficient.
PABLO	GP	DM	YES	S	Langdon, William B.	Large Scale Bioinformatics Data Mining with Parallel Genetic Programming on Graphics Processing Units	PARALLEL AND DISTRIBUTED COMPUTATIONAL INTELLIGENCE	2010	A suitable single instruction multiple data GP interpreter can achieve high (Giga GPop/second) performance on a SIMD GPU graphics card by simultaneously running multiple diverse members of the genetic programming population. SPMD dataflow parallelisation is achieved because the single interpreter treats the different GP programs as data. On a single 128 node parallel nVidia GeForce 8800 GTX CPU, the interpreter can out run a compiled approach, where data parallelisation comes only by running a single program at a time across multiple inputs.The Rapid Mind GPGPU Linux C++ system has been demonstrated by predicting ten year+ outcome of breast cancer from a dataset containing a million inputs. NCBI GEO GSE3494 contains hundreds of Affymetrix HG-U133A and HG-U133B GeneChip biopsies. Multiple GP runs each with a population of five million programs winnow useful variables from the chaff at more than 500 million GPops per second. Sources available via FTP.
PABLO	GP		YES	S	Ebner, Marc	A Real-Time Evolutionary Object Recognition System	GENETIC PROGRAMMING	2009	We have created a real time evolutionary object recognition system. Genetic Programming is used to automatically search the space of possible computer vision programs guided through user interaction. The user selects the object extracted with the mouse pointer and follows it over multiple frames of a video sequence. Several different, alternative algorithms are evaluated in the background for each input image. Real-time performance is achieved through the use of the GPU for image processing operations.
PABLO	GP		NO	B	Robilliard, Denis; Marion, Virginie; Fonlupt, Cyril	High Performance Genetic Programming on GPU	WORKSHOP ON BIO-INSPIRED ALGORITHMS FOR DISTRIBUTED SYSTEMS - BADS 2009	2009	The availability of low cost powerful parallel graphics cards has stimulated the port of Genetic Programming (C; P) on Graphics Processing Units (GPUs). Our work focuses on the possibilities offered by Nvidia G80 GPUs when programmed in the CUDA language. We compare two parallelization schemes that evaluate several GP programs in parallel. We show that the fine grain distribution of computations over the elementary processors greatly impacts performances. We also present memory and representation optimizations that further enhance computation speed, up to 2.8 billion GP operations per second. The code has been developed with the well known ECJ library.
PABLO	GP		YES	J	Langdon, W. B.; Harrison, A. P.	GP on SPMD parallel graphics hardware for mega Bioinformatics data mining	SOFT COMPUTING	2008	We demonstrate a SIMD C++ genetic programming system on a single 128 node parallel nVidia GeForce 8800 GTX GPU under RapidMind's GPGPU Linux software by predicting ten year+ outcome of breast cancer from a dataset containing a million inputs. NCBI GEO GSE3494 contains hundreds of Affymetrix HG-U133A and HG-U133B GeneChip biopsies. Multiple GP runs each with a population of 5 million programs winnow useful variables from the chaff at more than 500 million GPops per second. Sources available via FTP.
PABLO	GP		YES	B	Wilson, Garnett; Banzhaf, Wolfgang	Linear Genetic Programming GPGPU on Microsoft's Xbox 360	2008 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION, VOLS 1-8	2008	We describe how to harness the graphics processing abilities of a consumer video game console (Xbox 360) for general programming on graphics processing unit (GPGPU) purposes. In particular, we implement a linear GP (LGP) system to solve classification and regression problems. We conduct inter- and intra-platform benchmarking of the Xbox 360 and PC, using GPU and CPU implementations on both architectures. Platform benchmarking confirms highly integrated CPU and GPU programming flexibility of the Xbox 360, having the potential to alleviate typical GPGPU decisions of allocating particular functionalities to CPU or GPU.
PABLO	GP		NO	B	Langdon, W. B.	A Fast High Quality Pseudo Random Number Generator for Graphics Processing Units	2008 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION, VOLS 1-8	2008	Limited numerical precision of nVidia GeForce 8800 GTX and other GPUs requires careful implementation of PRNGs. The Park-Miller PRNG is programmed using G80's native Value4f floating point in RapidMind C++. Speed up is more than 40. Code is available via ftp cs.ucl.ac.uk genetic/gp-code/random-numbers/gpu_park-miller.tar.gz
PABLO	GP		YES	B	Harding, Simon	Evolution of Image Filters on Graphics Processor Units Using Cartesian Genetic Programming	2008 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION, VOLS 1-8	2008	Graphics processor units are fast, inexpensive parallel computing devices. Recently there has been great interest in harnessing this power for various types of scientific computation, including genetic programming. In previous work, we have shown that using the graphics processor provides dramatic speed improvements over a standard CPU in the context of fitness evaluation. In this work, we use Cartesian Genetic Programming to generate shader programs that implement image filter operations. Using the GPU, we can rapidly apply these programs to each pixel in an image and evaluate the performance of a given filter. We show that we can successfully evolve noise removal filters that produce better image quality than a standard median filter.
PABLO	GP		YES	B	Langdon, W. B.	Evolving GeneChip Correlation Predictors on Parallel Graphics Hardware	2008 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION, VOLS 1-8	2008	A GPU is used to datamine five million correlations between probes within Affymetrix HG-U133A probesets across 6685 human tissue samples from NCBI's GEO database. These concordances are used as machine learning training data for genetic programming running on a Linux PC with a RapidMind OpenGL GLSL backend. GPGPU is used to identify technological factors influencing High Density Oligonuclotide Arrays (HDONA) performance. GP suggests mismatch (PM/MM) and Adenosine/Guanine ratio influence microarray quality, Initial results hint that Watson-Crick probe self hybridisation or folding is not important. Under GPGPGPU an nVidia GeForce 8800 GTX interprets 300 million GP primitives/second (300 MGPops, approx 8 GFLOPS).
PABLO	GP	ML	YES	S	Langdon, W. B.; Banzhaf, Wolfgang	A SIMD interpreter for genetic programming on GPU graphics cards	GENETIC PROGRAMMING, PROCEEDINGS	2008	Mackey-Glass chaotic time series prediction and nuclear protein classification show the feasibility of evaluating genetic programming populations directly on parallel consumer gaming graphics processing units. Using a Linux KDE computer equipped with an nVidia GeForce 8800 GTX graphics processing unit card the C++ SPMD interpretter evolves programs at Giga GP operations per second (895 million GPops). We use the RapidMind general processing on GPU (GPGPU) framework to evaluate an entire population of a quarter of a million individual programs on a non-trivial problem in 4 seconds. An efficient reverse polish notation (RPN) tree based GP is given.
PABLO	GP		YES	S	Ando, Jun; Nagao, Tomoharu	Fast evolutionary image processing using multi-GPUs	2007 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS, VOLS 1-8	2007	In this paper, the authors propose a fast evolutionary image processing system. The authors employ Graphics Processing Unit (GPU) to Automatic Construction of Tree-structural Image Transformation (ACTIT) for the purpose of reducing optimization time. Be-sides, the system calculates in parallel by using multiple GPUs for the fast processing. The optimization speed of the proposed system is several hundred times faster than that of the ordinary ACTIT. Experimental results show that the proposed system is effective.
PABLO	GP		NO	S	Harding, Simon; Banzhaf, Wolfgang	Fast genetic programming on GPUs	Genetic Programming, Proceedings	2007	As is typical in evolutionary algorithms, fitness evaluation in CP takes the majority of the computational effort. In this paper we demonstrate the use of the Graphics Processing Unit (GPU) to accelerate the evaluation of individuals. We show that for both binary and floating point based data types, it is possible to get speed increases of several hundred times over a typical CPU implementation. This allows for evaluation of many thousands of fitness cases, and hence should enable more ambitious solutions to be evolved using GP.
ANTONIO	GA		YES	S	Wodecki, Mieczyslaw; Bozejko, Wojciech; Karpinski, Michaffl; Pacut, Maciej	Multi-GPU Parallel Memetic Algorithm for Capacitated Vehicle Routing Problem	PARALLEL PROCESSING AND APPLIED MATHEMATICS (PPAM 2013), PT II	2014	The goal of this paper is to propose and test a new memetic algorithm for the capacitated vehicle routing problem in parallel computing environment. In this paper we consider a simple variation of the vehicle routing problem in which the only parameter is the capacity of the vehicle and each client only needs one package. We analyze the efflciency of the algorithm using the hierarchical Parallel Random Access Machine (PRAM) model and run experiments with code written in CUDA.
